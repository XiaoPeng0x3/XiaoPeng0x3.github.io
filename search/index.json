[{"content":"基础命令 首先需要启动redis服务，可以通过sudo systemctl start redis，一般来说可以通过配置来使得redis进行开启自启。\n在使用时，可以使用:\n1 redis-cil 来登入redis\n创建一个字段 set 由于redis的数据结构就是基础key-value的形式，所以创建对象时要指定对象的名称和值。\n创建姓名键值对\n1 set name \u0026#34;Bob\u0026#34; 这样就创建好了一个{name:Bob}的数据结构\n创建数值型\n1 set age 18 如果需要添加新的成员，可以使用set来创建。需要注意的是，创建出来的key-value的value的类型是字符串类型。但是对于一些数据(长得像整数)，那么redis还可以对这个数据进行自增自减操作。\nincr和decr(整形自增自减) 自增\n1 incr age 这样在此进行查询的时候，age就变为19，但它的类型依旧是字符串类型。\n自减\n1 decr age 每次自增自减的值都是1\nincrby和decrby 可以指定key增长的数目\n增加2\n1 incrby age 2 减小2\n1 decrby age 2 get get可以获取对应key的value\n获取name的名称\n1 get name 获取age的值\n1 get age 答案会返回18\ntype 使用type可以查看一个key的数据类型\n查看age的类型\n1 type age 需要注意的是，这类数字在底层都是按照字节数组来存储的，对于数字来说，直接把数字转换为二进制数组来存储\n查看name的类型\n1 type name mset 可以一次设置多个键值对类型\n1 mset name \u0026#34;bob\u0026#34; age 18 school \u0026#34;xiaoxue\u0026#34; 这样就设置好了键值对信息。需要注意的是，这是一个原子操作，如果前面有设置失败的字段，那么后面的字段也不会成功的设置。\nmget 同样的，这个命令可以一下次获取多个key的值\n1 mget name age school 这样就会得到多个返回的值。\nexpire 和 ttl 由于redis是基于内存的nosql数据库，所以其数据存储的越多，那么占用的内存也就越多(一个典型的例子是短信验证码),我们可以给这个数据设置一个有效期(默认单位是秒)\n给age设置20秒的有效期\n1 expire age 20 设置完后可以使用ttl(time to live)来获取有效剩余时间\n1 ttl age 总结 这是一些基础命令！\n","date":"2025-03-12T22:00:14+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A41/","title":"基础命令1"},{"content":"员工管理系统 这是一个综合了前后端、开发流程比较完整的一个简单管理系统。项目中已经提供好了前端页面，但是还需要我们自己去编写后端返回给前端的请求。\n其中需要编写的请求就是增删改查这四个基础的请求。在这个项目中，总共有两个需要创建的表，即员工表和部门表。所有的增删查改任务都是基于这两张表来开展的。\nRestAPI风格 与传统的GET和POST请求不同，RestAPI把每项不同的操作划分给不同的动作\nGET\n可以只负责查询数据\nPOST\n可以负责新增数据\nPUT\n可以负责修改数据\nDelete\n可以负责删除数据\n单单从url里面来说，这四种操作的url几乎相同，只是行为不同，这样就使得更加规范\n项目工程结构 工程的结构总共分为几大类\nController\n专门负责处理来自前端的数据\nMapper\n专门负责处理来自数据库的部分\nService\n负责业务逻辑，如调用来自Mapper的接口，拿到数据库里面的数据后进行各种处理。\nPojo\n负责存放一些实体类，如表里面的Emp，User对象等。\n查询数据 项目中有一个功能就是去实现目前所有部门，用sql语句来表示可能就是\n1 select name, create_time, update_time from dep; 让我们先来熟悉一下思路\nMapper\n在Mapper层需要定义查询数据库的接口，因为查询sql很简短，所以我们可以直接写在java代码里面。\n1 2 3 4 5 @Mapper public interface DeptMapper { //查询所有部门数据 @Select(\u0026#34;select id, name, create_time, update_time from dept\u0026#34;) List\u0026lt;Dept\u0026gt; list(); Mapper是开启容器化注入的一个注解，其实很简单，需要实现对部门的任何操作都可以写在这个DeptMapper当中。\nService\n然后我们需要在Service层获取在Mapper层得到的来自数据库的信息。在service层中，我们定义了Dept接口和DeptImpl实现对象，在这里可以编写对应的方法来获取得到的数据库对象\n1 2 3 4 5 6 @Autowired private DeptMapper deptMapper; @Override public List\u0026lt;Dept\u0026gt; list() { return deptMapper.list(); } Controller\n在controller中调用Service层处理好的数据，然后经过统一的响应格式(Result)返回\n1 2 3 4 5 6 7 8 9 @Autowired private DeptService deptService; //@RequestMapping(value = \u0026#34;/depts\u0026#34; , method = RequestMethod.GET) @GetMapping public Result list(){ List\u0026lt;Dept\u0026gt; deptList = deptService.list(); return Result.success(deptList); } 需要注意的是，在填写url时，我们可以直接指定访问该url的动作，即使用GET方法即可\n1 2 3 4 5 @GetMapping public Result list(){ List\u0026lt;Dept\u0026gt; deptList = deptService.list(); return Result.success(deptList); } 这就是查询数据的操作。\n增加数据 增加一条数据的sql原语句就是\n1 insert into dep(字段名) values(值) 在部门字段中，如果我们需要新添加一个部门，那么在前端页面上只需要输入其姓名即可，然而这个部门包含以下几个属性\n1 2 3 4 5 6 7 8 9 10 mysql\u0026gt; desc dept; +-------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------------+--------------+------+-----+---------+----------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | name | varchar(10) | NO | UNI | NULL | | | create_time | datetime | NO | | NULL | | | update_time | datetime | NO | | NULL | | +-------------+--------------+------+-----+---------+----------------+ 4 rows in set (0.00 sec) 其中，后面两个字段需要在我们成功创建对象的时候就添加为创建时的时间now()，而如何传递name字段呢，其实在前端向后端传递数据时，其传递的数据就是json的键值对，我们可以利用RequestBody这个属性来填写该字段，并把该字段的create_time和update_time更新为创建时的时间即可。\n1 2 3 4 // 新增部门 // 需要注意的是后面的参数是来自我们自己封装的Dept对象，所以后面要用驼峰命名法，即和dept里面的数据名一致 @Insert(\u0026#34;insert into dept(name, create_time, update_time) values (#{name}, #{createTime}, #{updateTime})\u0026#34;) void insert(Dept dept); 需要注意的是，在pojo.Dept中，后面两个字段都是按照驼峰命名法来命名的，而数据库中的变量是以下划线来进行分割的，这里有一个变量名转换依赖，在使用这个依赖后就可以将我们的字段成功转换。\n为了防止我以后看到这段代码疑惑，数值在代码中传递的方向是\nController\n获取name，并添加时间字段\nService\n将这个数据传递到Service层中\nMapper\n再传递到Mapper中，然后插入数据。\n显然，在数据流动过程中，如果需要执行查询等这类不需要修改数据库的内容，那么数据就是从数据库出发，返回到controller后完成响应。\n如果需要执行删除、修改等这类的操作，那么数据就是从controller层出发，传递到数据库后，完成响应。\n删除数据 同样的，在Mapper层中定义好删除接口，在Service层中实现逻辑，然后在Controller层中完成响应\n1 2 3 // 根据id来删除 @Delete(\u0026#34;delete from dept where id = #{id}\u0026#34;) void delete(int id); 修改数据 可以根据传进来的id来实现修改部门\n1 2 3 4 5 6 @PutMapping(\u0026#34;{id}\u0026#34;) public Result update(@RequestBody Dept dept){ dept.setUpdateTime(LocalDateTime.now()); deptService.update(dept); return Result.success(); } 在Service层\n1 2 3 4 @Override public void update(Dept dept) { deptMapper.update(dept); } 在Mapper层\n1 2 3 // 修改数据 @Update(\u0026#34;update dept set name = #{name}, update_time = #{updateTime} where id = #{id}\u0026#34;) void update(Dept dept); 总结 这里实现了基本的增删查改功能。现在我们来梳理以下这样一个前后端项目需要哪些条件。\n环境搭建 准备好数据库连接\n分包编写代码。在Mapper层中编写操作数据库有关的代码；在Service层实现业务逻辑；在Controller层实现响应。\nMapper层中都是接口对象，下面是一个包目录的文件结构\n","date":"2025-03-09T20:41:19+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E5%91%98%E5%B7%A5%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E6%A1%88%E4%BE%8B/","title":"员工管理系统案例"},{"content":"增删查改 增删查改算是十分重要且基础的部分，这里来跟着文档来实现一下如何进行增删改查。\nMybatis连接数据库 需要我们在application.properties下配置好对应的内容\n1 2 3 4 5 6 7 8 9 10 11 #驱动类名称 spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver #数据库连接的url spring.datasource.url=jdbc:mysql://localhost:3306/mybatisEmp # 数据库用户名称 spring.datasource.username=root # 登录密码 spring.datasource.password=123456 删除 在Mapper层实现删除的接口，对于删除语句来说，其选择的注释就是@Delete，其中编写对应的删除语句即可。我们需要实现一个根据ID来删除的一个操作。\n参数传递 在Mapper层中我们可以编写EmpMapper接口，其中，为了更加灵活，我们可以根据传进来的ID来实现删除逻辑\n1 2 3 4 5 6 @Mapper public interface EmpMapper { // 删除 @Delete(\u0026#34;DELETE from emp where id = #{id}\u0026#34;) public int deleteEmpById(Integer id); } 使用Mapper注释可以将后续实例化的对象通过容器进行管理，后续我们只需要使用AutoWired注释即可。可以在test文件下进行测试。在测试时，每个测试都要写成一个函数，并且要加上@Test注释。\n1 2 3 4 5 @Test public void deleteByPrimaryKey() { int i = empMapper.deleteEmpById(17); System.out.println(\u0026#34;Return Val Of Delete is \u0026#34; + i); } sql注入问题 当使用拼接sql语句去进行某些验证业务时，精心构造的参数会跳过验证，从而起到sql注入攻击的效果。假设我们使用的是sql拼接的方式进行验证，例如，我们要做登录验证。\n一般，数据库会存储用户名和加密后的密码(应该不是明文密码)，当我们进行登录是时，假设是在进行查询操作。\n1 select count(*) where userName = \u0026#39;xxx\u0026#39; and password = \u0026#39;xxx\u0026#39;; 当使用拼接sql时，我们可以构造出来count(*)永远大于0的操作，即password在传递时为' or '1' = '1,这样，拼接后的sql语句就是\n1 select count(*) from emp where userName = \u0026#39;xxx\u0026#39; and password = \u0026#39;\u0026#39; or \u0026#39;1\u0026#39; = \u0026#39;1\u0026#39;; 而1 = 1永远成立，所以这条sql相当于\n1 select count(*) from emp; sql预编译 解决sql注入可以通过预编译的方式去避免。在预编译时，传递的关键参数都是利用占位符去占用，例如上面这条sql语句就会变为\n1 select count(*) from emp where userName = ? and password = ?; 当有参数传递时，就会将?替换为对应的参数，从而避免了sql拼接的问题。在上面传递参数的sql语句中，一共有两种传递参数的办法\n1 2 #{id} ${id} 这两种方式都可以起到参数传递的作用，不过#{id}的方式是预编译sql，可以解决sql注入的问题。\n插入数据 在mysql中，插入数据的sql语句一般是\n1 insert into xxx(字段名) values (xxxx); 使用的注解也是@Insert，当插入的值过多，就可以把这些值封装到一个对象里面，把需要插入的参数使用#{xx}的方式插入即可，这样可以防止sql注入，同时预编译还可以提高查询效率。\n当需要进行模糊搜索时，一般会用到通配符搜索，在使用通配符的时候，有些通配符符号是无法通过#{xx}的形式去拼接的，例如，我想要搜索所有包含张的姓名\n1 select name from user where name like \u0026#39;%张%\u0026#39;; 那么在传递参数的时候，需要把%也传递进去，就像下面一样\n1 2 3 4 5 6 7 8 9 @Mapper public interface EmpMapper { @Select(\u0026#34;select * from emp \u0026#34; + \u0026#34;where name like \u0026#39;%${name}%\u0026#39; \u0026#34; + \u0026#34;and gender = #{gender} \u0026#34; + \u0026#34;and entrydate between #{begin} and #{end} \u0026#34; + \u0026#34;order by update_time desc\u0026#34;) public List\u0026lt;Emp\u0026gt; list(String name, Short gender, LocalDate begin, LocalDate end); } 如果要使用占位参数来编写sql，那么这个句子就变成了\n1 select name from user where name like \u0026#39;%?%\u0026#39; 这样就会出现编译错误，而使用直接拼接的${}话，又会引发sql注入问题，所以可以使用sql的库函数即concat函数来拼接。\n1 2 3 4 5 6 7 8 9 10 11 @Mapper public interface EmpMapper { @Select(\u0026#34;select * from emp \u0026#34; + \u0026#34;where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026#34; + \u0026#34;and gender = #{gender} \u0026#34; + \u0026#34;and entrydate between #{begin} and #{end} \u0026#34; + \u0026#34;order by update_time desc\u0026#34;) public List\u0026lt;Emp\u0026gt; list(String name, Short gender, LocalDate begin, LocalDate end); } 这样也可以实现预编译，把中间的#{name}替换掉,在预编译后就变成了\n1 select name from user where name like concat(\u0026#39;%\u0026#39;, ?, \u0026#39;%\u0026#39;); XML编写 可以直接把用到的sql语句写到XML文件里面，这样当sql语句开始变得复杂的时候，就可以方便的管理一些sql语句，从而避免将sql语句直接写在java代码里面。\n书写规范 其书写格式一般是\n1 2 3 \u0026lt;mapper namespace=\u0026#34;xxx.xxx.xxx\u0026#34;\u0026gt; \u0026lt;/mapper\u0026gt; 不同的sql语句之间标签不一致，查询语句需要用\u0026lt;select\u0026gt;标签包裹，同理的，例如\u0026lt;insert\u0026gt;、\u0026lt;delete\u0026gt;、\u0026lt;update\u0026gt;\n同时，还需要在这些标签中注明方法名和方法的返回值,假设我们要查询\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;mapper namespace=\u0026#34;com.itheima.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;!--查询操作--\u0026gt; \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.itheima.pojo.Emp\u0026#34;\u0026gt; select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender = #{gender} and entrydate between #{begin} and #{end} order by update_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 其中id=\u0026quot;list\u0026quot;说明这个查询函数的函数名为list，resultType=xxx说明其返回值类型是xxx，然后在标签中间编写sql语句即可。\n需要注意，可以直接把简单的sql以注解的形式写道java代码里面，也可以写到xml文件里面。越短越简单的sql语句可以写到java代码里面。\n更新数据 同样的，我们可以使用insert来向表里面插入某些数据，也可以使用update来更新一些数据，如果我们不指定所有的字段，那么未指定的字段将会被设置为null,但是这并不是我们希望看到的，有时候只需要修改一两条信息，其它的信息不用做出修改，这个时候我们就可以使用动态sql来避免传递空子段。\n动态SQL 动态SQL是指前端传递过来的参数个数是不确定的，这就要求我们不可以将sql语句写死，而是根据传递结果来确定sql语句的书写，这里就用到了if标签。\n语法 1 2 3 \u0026lt;if test=\u0026#34;判断语句\u0026#34;\u0026gt; \u0026lt;/if\u0026gt; 例如，之前的一条查询语句为\n1 2 3 4 5 6 7 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.itheima.pojo.Emp\u0026#34;\u0026gt; select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender = #{gender} and entrydate between #{begin} and #{end} order by update_time desc \u0026lt;/select\u0026gt; 我们就可以根据name gender entrydate这些字段是否为空来进行查询判断\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.itheima.pojo.Emp\u0026#34;\u0026gt; select * from emp where \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender != null\u0026#34;\u0026gt; and gender = #{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin!= null and end != null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; order by update_time desc \u0026lt;/select\u0026gt; 当某些字段为空时，即未通过test测试，那么就不会查询该字段。\n问题 但是这样就又会引发一些问题，当name字段为空时，这段SQL语句会变成\n1 2 3 4 5 6 7 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.itheima.pojo.Emp\u0026#34;\u0026gt; select * from emp where and gender = #{gender} and entrydate between #{begin} and #{end} order by update_time desc \u0026lt;/select\u0026gt; 可以发现,，where后面多跟了一个and导致我们的语法发生了错误，当然也有解决办法，就是去使用\u0026lt;where\u0026gt;标签\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.itheima.pojo.Emp\u0026#34;\u0026gt; select * from emp \u0026lt;where\u0026gt; \u0026lt;!-- if做为where标签的子元素 --\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; and name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender != null\u0026#34;\u0026gt; and gender = #{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin != null and end != null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by update_time desc \u0026lt;/select\u0026gt; 更新某些数据 同样的，只有在前端传递管来的值不为null时才对里面的值进行修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;https://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.itheima.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;!--更新操作--\u0026gt; \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update emp set \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt; username=#{username}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; name=#{name}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender != null\u0026#34;\u0026gt; gender=#{gender}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image != null\u0026#34;\u0026gt; image=#{image}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;job != null\u0026#34;\u0026gt; job=#{job}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;entrydate != null\u0026#34;\u0026gt; entrydate=#{entrydate}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;deptId != null\u0026#34;\u0026gt; dept_id=#{deptId}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt; update_time=#{updateTime} \u0026lt;/if\u0026gt; where id=#{id} \u0026lt;/update\u0026gt; \u0026lt;/mapper\u0026gt; 可是这样做又会引起sql语句的语法错误，例如当只存在第一个字段而不存在后面那些字段时，下面的语句就是\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;https://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.itheima.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;!--更新操作--\u0026gt; \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update emp set username=#{username}, where id=#{id} \u0026lt;/update\u0026gt; \u0026lt;/mapper\u0026gt; 也就是后面多加了一个逗号，同样的，我们也可以使用\u0026lt;set\u0026gt;标签来修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;https://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.itheima.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;!--更新操作--\u0026gt; \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update emp \u0026lt;!-- 使用set标签，代替update语句中的set关键字 --\u0026gt; \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt; username=#{username}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; name=#{name}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender != null\u0026#34;\u0026gt; gender=#{gender}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image != null\u0026#34;\u0026gt; image=#{image}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;job != null\u0026#34;\u0026gt; job=#{job}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;entrydate != null\u0026#34;\u0026gt; entrydate=#{entrydate}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;deptId != null\u0026#34;\u0026gt; dept_id=#{deptId}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt; update_time=#{updateTime} \u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id=#{id} \u0026lt;/update\u0026gt; \u0026lt;/mapper\u0026gt; sql引用 对于一些重复的sql片段，我们可以使用片段包裹的方式来进行引入\n1 2 3 4 5 \u0026lt;sql id=\u0026#34;name\u0026#34;\u0026gt; select name, age, gender from user \u0026lt;/sql\u0026gt; 这个时候，如果想要引用上面这个sql语句，就可以使用include标签来进行引用\n1 2 3 \u0026lt;include refid=\u0026#34;name\u0026#34;\u0026gt; where id = 1 \u0026lt;/include\u0026gt; 这样就可以把重复的语句选出来。\n总结 这就是Mybatis连接数据库的所有操作，加油~\n","date":"2025-03-08T15:38:35+08:00","permalink":"https://XiaoPeng0x3.github.io/p/mybatis%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/","title":"Mybatis增删查改"},{"content":"springboot 解耦是一种很好的设计规范。Dao层负责解析数据，那么在service层里面，我们就需要new来自Dao层的实例对象来进行方法的调用。同理在Controller层我们需要new来自service层的对象，这样做如果后续Dao和Controller层的实现发生改变时，那么调用这两个的实例对象也需要修改。在spring里面也提供了解耦的方法，就是上交管理权限和容器注入。\n把new实例对象的操作交给spring来使用，这样spring就会使用容器来管理存储这些对象，并在使用时通过调用容器的方式来传递参数。\n解耦 将需要解耦的类使用Component，需要管理的对象使用AutoWired来进行注解。并且，为了更好的标注Component的作用，还衍生出了这些类的不同注解，例如：\n@Service：注解服务层 @Controller：注解控制层 @Repository：数据访问类 Mysql 在Mysql中，现在来总结一下事务和索引这两个不太熟悉的概念。\n事务 只有InnodeDB支持事务，其它类型的数据库均不支持。\n事务可以理解为一把锁。除此之外，当事物执行失败的时候，它还支持回归事物，即如果某条sql语句执行失败，那么可以通过事务回滚来回到执行前的状态。\n一些八股 数据库为了解决并发场景提出了事务的概念，而事务包括下面几个特点\n原子性(A)\n事务要么提交成功，要么提交失败后回滚，不存在事务中某一部分的值成功修改，而一部分值没有发生修改。其中失败回滚是通过日志系统来完成的，即在修改数据前先把旧的数据写入undo_log里面，当需要失败回滚时，就可以把数据还原。\n一致性(C)\n一致性是指事务确保了数据的合理性和正确性。合理性是指值的变量在一个合理的范围内\n隔离性(I)\n不同事务之间存在隔离性，并且隔离性也分等级，隔离等级越高，并发效果越好，但是效率越差。\n持久性(D)\n数据库就是专门为持久化数据而准备的\n在此，我们用两个事物A,B来分析一下可能出现的情况。\n脏读 顾名思义，脏读就是读取了一个错误的数据。\n假设一种情况，事务A修改了一些数据，但是还未来得及提交，此时事务B再读这些数据就是发生了脏读。\n幻读 幻读也是发生在查询数据之间的，例如在事务A里面我们要进行查询数据，在两条查询语句之间，事务B插入了新的数据；\n这会导致A查询出来的数据前后结果不一致，注意，幻读一般指查询的集合前后不一致，也就是查询出来的行数前后不同。\n不可重复读 与幻读相似，不过一般指的是某个值而并非某一行数据不可重复读。\n索引 索引是为了加快查询速度而抽象出来的一种数据结构。其中索引使用的数据结构是B+树。\nB+ 树 B+树是一种特殊的数据结构，其数据全部存储在叶子结点，而非叶子结点存储的是下一级的物理地址，与B树不同的的地方有\nB+树的数据只在叶子结点保存 其叶子结点是双向链表连接 查询效率高 但是本质上还是空间换时间的机制来加快查找速度。\n在mysql中，primary key以及unique值会自动创建索引，也就是默认索引，根据索引来查询数据的效率是最高的。\n下面是创建索引的sql语句\n1 create index idx_user_name on user(name) 一般创建的索引命名如下\nidx是代之索引index，user是表名，name是根据哪个字段创建索引，意思就是给user表的name字段创建一个索引。\n","date":"2025-03-06T13:33:42+08:00","permalink":"https://XiaoPeng0x3.github.io/p/springboot%E5%92%8Cmysql/","title":"Springboot和Mysql"},{"content":"Springboot 在IDEA里面配置好springboot的开发环境后，我们就可以进行一个简单的Springboot程序开发了。\n创建controller对象 创建controller包，这个包专门处理来自前端的请求，并把对应的请求返回到前端。下面是我们的一个简单入门程序\n1 2 3 4 5 6 7 8 9 10 11 12 package com.zxp.springbootstart.controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HelloController { @RequestMapping(\u0026#34;/hello\u0026#34;) public String hello() { return \u0026#34;Hello World\u0026#34;; } } 其中，RequestMapping指定了映射的url，只要我们访问对应的这个hello，那么我们就会收到来自后端返回的Hello World。\n参数初始化 如果参数名和前端传递过来的参数名一致，例如下面这个GET请求\n1 localhost:8080/simpletest?name=Bob\u0026amp;age=40 这个URL传递了两个参数，即name和age，只要我们的函数形参与传递过来的参数一致，那么就可以自动初始化好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package com.zxp.springbootstart.controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; @RestController public class RequestController { @RequestMapping(\u0026#34;/simpletest\u0026#34;) public String simpletest(String name, Integer age) { System.out.println(\u0026#34;Name: \u0026#34; + name); System.out.println(\u0026#34;Age: \u0026#34; + age); return \u0026#34;success\u0026#34;; } } 如果我们不希望一定把参数名称给写死，那么就可以使用一个注解，@RequestParam，这个注解会自动把前端传递过来的参数给初始化好\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package com.zxp.springbootstart.controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; @RestController public class RequestController { @RequestMapping(\u0026#34;/simpletest\u0026#34;) public String simpletest(@RequestParam(\u0026#34;name\u0026#34;) String userename, Integer age) { System.out.println(\u0026#34;Name: \u0026#34; + userename); System.out.println(\u0026#34;Age: \u0026#34; + age); return \u0026#34;success\u0026#34;; } } 多参数传递 假设传递了很多参数，例如name age address 等等，最好的做法是把这些参数全部都封装为一个类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package com.zxp.springbootstart.pojo; public class User { private String name; private Integer age; public User(String name, int age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \u0026#34;User [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } } 这样我们在传递参数的时候只需要传递User即可。\n数组集合参数 当有许多参数的名称一致时，例如前端传递了一个多选项的参数，我们可以使用数组或者集合来存储这些参数。\n使用数组来进行保存\n1 2 3 4 5 @RequestMapping(\u0026#34;/arrayParam\u0026#34;) public String arrayParam(String[] hobby) { System.out.println(Arrays.toString(hobby)); return \u0026#34;success\u0026#34;; } 也可以使用集合来进行保存\n1 2 3 4 5 @RequestMapping(\u0026#34;/listParam\u0026#34;) public String listParam(@RequestParam(\u0026#34;hobby\u0026#34;) List\u0026lt;String\u0026gt; hobby) { System.out.println(hobby); return \u0026#34;success\u0026#34;; } 时间参数 后端需要使用后端controller方法中，需要使用Date类型或LocalDateTime类型，来封装传递的参数。时间参数需要按照一定的参数进行传递\n1 2 3 4 5 @RequestMapping(\u0026#34;/dateParam\u0026#34;) public String dateParam(@DateTimeFormat(pattern = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;) LocalDateTime updateTime){ System.out.println(updateTime); return \u0026#34;OK\u0026#34;; } 需要指定pattern，在前端传递时间参数的时候也需要按照一定的方式去传递时间参数。\nJson Json是键值对类型的数据，其键是字符串类型，下面一个就是一个json数据的示例\n1 2 3 4 { \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;age\u0026#34;: 20 } 在传递json参数的时候需要使用RequestBody来进行注解。\n路径参数 在传递参数的时候，还可以传递一些路径参数，需要使用@PathVariable来接受参数\n1 2 3 4 5 @RequestMapping(\u0026#34;/path/{id}\u0026#34;) public String path(@PathVariable Integer id) { System.out.println(id); return \u0026#34;success\u0026#34;; } 在传递参数的时候就可以使用这样的URL\n1 localhost:8080/path/10 那么在后端得到的数据就是10\n统一响应结果 在返回响应时，如果每次都是用不同的类型返回，那么前端每次都得处理不同的数据格式，我们可以把返回结果封装为一个类来进行使用。\n这里又可以分为三种情况\n只需要响应状态 需要返回数据 响应错误 其中需要封装好三个变量\n1 2 3 private int code; private String msg; private Object data; 响应案例 首先将网页等静态资源全部存储在static目录下，在这个案例中，我们需要掌握的技巧有：\n如何动态的获取文件路径 stream流式修改数据 响应数据 动态获取地址\n1 String file = this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); 中间处理\n将前端传过来的数据进行替换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); if (\u0026#34;1\u0026#34;.equals(gender)) { emp.setGender(\u0026#34;man\u0026#34;); } else if (\u0026#34;2\u0026#34;.equals(gender)) { emp.setGender(\u0026#34;woman\u0026#34;); } String job = emp.getJob(); if (\u0026#34;1\u0026#34;.equals(job)) { emp.setJob(\u0026#34;讲师\u0026#34;); } else if (\u0026#34;2\u0026#34;.equals(job)) { emp.setJob(\u0026#34;班主任\u0026#34;); } else if (\u0026#34;3\u0026#34;.equals(job)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } } ); 在前端传递过来的数据中，其中gender和job都是id来标志的，我们需要将这些数据进行人为替换后再将数据写回前端。\n写回前端时可以使用我们封装好的Result作为统一结果返回。\n1 return Result.success(empList); 开发规范 在开发时要注意分层，每个层只完成自己的那一部分任务即可。如果把所有的逻辑全部写在controller层不太规范。\n一般的，我们可以将这个逻辑划分为三个部分，即后端处理来自前端的响应controller层；响应后完成server服务；中间需要进行数据的可以再封装一个dao层来专门管理数据。\n我们来改造一下这个代码\n首先在dao层处理所有的获取资源操作，实现一个dao接口\n1 2 3 4 public interface EmpDao{ // 获取资源并将资源封装到集合里面 public List\u0026lt;Emp\u0026gt; listEmp(){} } 实现这个接口\n1 2 3 4 5 6 7 8 @Override public List\u0026lt;Emp\u0026gt; listEmp() { // 返回listEmp //1. 解析前端页面 String file = this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); List\u0026lt;Emp\u0026gt; empList = XmlParserUtils.parse(file, Emp.class); return empList; } 实现service代码，这里负责处理数据，也就是业务逻辑.\n1 2 3 public interface EmpService { public List\u0026lt;Emp\u0026gt; listEmp(); } 在controller层对数据进行响应。\n1 2 3 4 5 6 7 private EmpService empService = new EmpServiceA(); @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result listEmp() { // 得到处理的listemp List\u0026lt;Emp\u0026gt; list = empService.listEmp(); return Result.success(list); } 这样做其实还不够规范，可以看到我们每次都是去new一个私有对象然后再去获取里面的方法，如果后面修改名称的话，这样就会导致代码报错。下次来记录怎么解决这个问题。\n","date":"2025-03-05T16:54:54+08:00","permalink":"https://XiaoPeng0x3.github.io/p/springboot%E5%85%A5%E9%97%A8%E4%BD%93%E9%AA%8C/","title":"Springboot入门体验"},{"content":"启动服务 在win下可以使用net启动mysql服务。\n首先打开具有管理员权限的cmd窗口，否则将会被禁止访问\n在窗口中输入\n1 net start mysql 然后就可以等待服务开启\n如果想要关闭服务，只需要输入\n1 net stop mysql 登录服务 在mysql中可以指定用户的登录，其命令格式如下‘\n1 mysql -u root -p password -u参数后面接的是登录时的用户名\n如果想要登出mysql，\n1 quit; 密码相关 修改密码 假设已经知道原来的密码，比如原来的密码是123，想要把密码修改为123456。\n登录mysql\n1 mysql -u root -p 123 修改表\n1 SET PASSWORD FOR \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; = \u0026#39;123456\u0026#39;; 刷新权限\n1 2 FLUSH PRIVILEGES; EXIT; 登出\n可以进行验证\n忘记密码 关闭所有正在运行的mysql服务\n1 net stop mysql 以跳过授权的方式登录\n1 mysqld --skip-grant-tables --skip-networking 直接登录\n1 mysql -u root 然后进行修改\n1 2 3 ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; FLUSH PRIVILEGES; EXIT; 重启mysql\n1 net start mysql 进行验证\n","date":"2025-03-04T10:22:06+08:00","permalink":"https://XiaoPeng0x3.github.io/p/mysql%E7%9A%84%E7%99%BB%E9%99%86/","title":"Mysql的登陆"},{"content":"Js的知识 引入方式 在html文件中引入js只需要输入\n1 2 3 \u0026lt;script\u0026gt; \u0026lt;/script\u0026gt; 即可，这个script标签在任意格子内即可，可以在head标签内，可以在body标签内，也可以在html标签的外面\n输出 一共有三种输出方式\n弹窗\n1 2 3 \u0026lt;script\u0026gt; alert(\u0026#34;Hello\u0026#34;) \u0026lt;/script\u0026gt; 输出到屏幕中\n1 2 3 \u0026lt;script\u0026gt; document.write(\u0026#34;Hello\u0026#34;) \u0026lt;/script\u0026gt; 控制台输出\n1 2 3 \u0026lt;script\u0026gt; console.write(\u0026#34;Hello\u0026#34;) \u0026lt;/script\u0026gt; 变量 js是弱语言类型，其不在乎变量的类型。可以使用var和let关键字声明一个变量，唯一的区别就是，var声明的关键字是全局关键变量，而let是局部变量。\n全局变量可以多次赋值，而局部变量不能多次赋值。\n1 2 var a = 10; // 局部变量 let b = 10; // 全局变量 除此之外还可以使用const声明常量，常量不可进行修改\n数据类型 可以使用typeof来查看一个变量或者值的类型，例如\n1 2 typeof 10 // number typeof \u0026#34;10\u0026#34; // string 运算符 js的运算符与其它语言不同的有===和!===这两个。由于js是静态语言，所以当将不同的类型相比较时，如果使用==，例如\n1 1 == \u0026#34;1\u0026#34; 输出结果为true\n如果想要比较这两个类型时，可以使用强相等\n1 1 === \u0026#34;1\u0026#34; 输出结果为false\n函数 直接声明一个函数，function关键字\n1 2 3 function add(a, b) { return a + b; } 使用var声明关键字\n1 2 3 var add = function(a, b) { return a + b; } json json是一种键值对形式的输入，其k值是string类型\n1 2 3 4 5 6 7 //定义json var jsonstr = \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;Tom\u0026#34;, \u0026#34;age\u0026#34;:18, \u0026#34;addr\u0026#34;:[\u0026#34;北京\u0026#34;,\u0026#34;上海\u0026#34;,\u0026#34;西安\u0026#34;]}\u0026#39;; alert(jsonstr.name); //json字符串--js对象 var obj = JSON.parse(jsonstr); alert(obj.name); Bom对象 统称为浏览器对象\n弹窗类的消息都是windows下的消息\n1 2 window.alert(\u0026#34;Hello BOM\u0026#34;); alert(\u0026#34;Hello BOM Window\u0026#34;); 1 2 3 4 5 6 7 8 9 alert(\u0026#39;提示信息\u0026#39;) confirm(\u0026#34;确认信息\u0026#34;) prompt(\u0026#34;弹出输入框\u0026#34;) open(\u0026#34;url地址\u0026#34;，“_black或_self”，“新窗口的大小”） close() 关闭当前的网页 1 2 3 4 5 6 7 setTimeout(函数，时间) 只执行一次 clearTimeout(定时器名称) 清除定时器，用于停止执行setTimeout()方法的函数代码。 setInterval(函数，时间) 无限执行 clearInterval() 方法用于停止 setInterval() 方法执行的函数代码。 location 对象\n对象用于获得当前页面的地址 (URL)，并把浏览器重定向到新的页面。\nwindow.location对象在编写时可不使用 window 这个前缀。 一些例子：\nlocation.herf = \u0026lsquo;url地址\u0026rsquo;\nlocation.hostname 返回 web 主机的域名\nDom操作 通过document来进行一系列操作，可以通过类，标签，id，name这些操作来获取html的元素，这也体现了为什么js可以对前端进行一些交互的原因，下面是一些例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 //1. 点亮灯泡 : src 属性值 var img = document.getElementById(\u0026#39;h1\u0026#39;); img.src = \u0026#34;img/on.gif\u0026#34;; //2. 将所有div标签的内容后面加上: very good (红色字体) -- \u0026lt;font color=\u0026#39;red\u0026#39;\u0026gt;\u0026lt;/font\u0026gt; var divs = document.getElementsByTagName(\u0026#39;div\u0026#39;); for (let i = 0; i \u0026lt; divs.length; i++) { const div = divs[i]; div.innerHTML += \u0026#34;\u0026lt;font color=\u0026#39;red\u0026#39;\u0026gt;very good\u0026lt;/font\u0026gt;\u0026#34;; } //3. 使所有的复选框呈现选中状态 var ins = document.getElementsByName(\u0026#39;hobby\u0026#39;); for (let i = 0; i \u0026lt; ins.length; i++) { const check = ins[i]; check.checked = true;//选中 } 事件绑定 大多数交互的事件由鼠标产生，例如点击、移动、缩放等这些操作，我们可以写两个按钮，点击这两个按钮的时候会弹出两个通知\n1 2 3 4 \u0026lt;body\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; id=\u0026#34;btn1\u0026#34; value=\u0026#34;事件绑定1\u0026#34; onclick=\u0026#34;on()\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; id=\u0026#34;btn2\u0026#34; value=\u0026#34;事件绑定2\u0026#34; onclick=\u0026#34;off()\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; 这里添加的监听时间是onclick，我们来实现一下这两个js函数\n1 2 3 function on() { alert(\u0026#34;开启\u0026#34;) } off函数\n1 2 3 function off() { alert(\u0026#34;关闭\u0026#34;) } 值得注意的是，在html样式里面，需要以函数调用的形式来指定，如果只写上函数名是不会调用的。\n","date":"2025-02-28T19:01:25+08:00","permalink":"https://XiaoPeng0x3.github.io/p/js%E7%9F%A5%E8%AF%86/","title":"Js知识"},{"content":"html 下面来看一些高级技巧\n视频video video的标签是\n1 \u0026lt;video src=\u0026#34;xxx\u0026#34; controls width=\u0026#34;\u0026#34;\u0026gt;\u0026lt;/video\u0026gt; 同样的指明路径就可以添加进来，初次之外还需要添加播放组件和进度条这些功能\n音频 audio 音频的标签\n1 \u0026lt;audio src= \u0026#34;XXX\u0026#34;\u0026gt;\u0026lt;/audio\u0026gt; 正文 正文的标签是\u0026lt;p\u0026gt;,使用正文可以包裹一些文字\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;!-- 超链接部分 --\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;!-- \u0026lt;style\u0026gt; h1 { color: blue; } \u0026lt;/style\u0026gt; --\u0026gt; \u0026lt;link rel=\u0026#34;style\u0026#34; href=\u0026#34;../css/news.css\u0026#34;/\u0026gt; \u0026lt;style\u0026gt; span { color: red; } .time { color: black; } #f { color: black; } a { color: red; text-decoration: none } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务 \u0026gt; 正文 \u0026lt;!-- \u0026lt;h1 style=\u0026#34;color: red;\u0026#34;\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; --\u0026gt; \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;span class=\u0026#34;time\u0026#34;\u0026gt; 2023年03月02日 21:50 \u0026lt;/span\u0026gt; \u0026lt;span id=\u0026#34;f\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;baidu.com\u0026#34;\u0026gt; 央视网 \u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;!-- 添加视频 --\u0026gt; \u0026lt;video src=\u0026#34;../video/1.mp4\u0026#34; controls width=\u0026#34;900\u0026#34;\u0026gt;\u0026lt;/video\u0026gt; \u0026lt;!-- 添加音频 --\u0026gt; \u0026lt;audio src=\u0026#34;../audio/1.mp3\u0026#34;\u0026gt;\u0026lt;/audio\u0026gt; \u0026lt;p\u0026gt; \u0026lt;strong\u0026gt;央视网消息\u0026lt;/strong\u0026gt; （焦点访谈）：党的十八大以来，以习近平同志为核心的党中央始终把解决粮食安全问题作为治国理政的头等大事，重农抓粮一系列政策举措有力有效，我国粮食产量站稳1.3万亿斤台阶，实现谷物基本自给、口粮绝对安全。我们把饭碗牢牢端在自己手中，为保障经济社会发展提供了坚实支撑，为应对各种风险挑战赢得了主动。连续八年1.3万亿斤，这个沉甸甸的数据是如何取得的呢？ \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; 人勤春来早，春耕农事忙。立春之后，由南到北，我国春耕春管工作陆续展开，春天的田野处处生机盎然。 \u0026lt;/p\u0026gt; \u0026lt;img src=\u0026#34;../img/1.jpg\u0026#34;\u0026gt; \u0026lt;p\u0026gt; 今年，我国启动了新一轮千亿斤粮食产能提升行动，这是一个新的起点。2015年以来，我国粮食产量连续8年稳定在1.3万亿斤以上，人均粮食占有量始终稳稳高于国际公认的400公斤粮食安全线。从十年前的约12200亿斤到2022年的约13700亿斤，粮食产量提高了1500亿斤。 \u0026lt;/p\u0026gt; \u0026lt;img src=\u0026#34;../img/2.jpg\u0026#34;\u0026gt; \u0026lt;p\u0026gt; 中国式现代化一个重要的中国特色是人口规模巨大的现代化。我们粮食生产的发展，意味着我们要立足国内，解决14亿多人吃饭的问题。仓廪实，天下安。保障粮食安全是一个永恒的课题，任何时候都不能放松。在以习近平同志为核心的党中央坚强领导下，亿万中国人民辛勤耕耘、不懈奋斗，我们就一定能够牢牢守住粮食安全这一“国之大者”，把中国人的饭碗牢牢端在自己手中，夯实中国式现代化基础。 \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 其中，加黑加粗的字体可以使用strong标签和b标签来进行表示。\n表格 表格的标签是table开头，在中间，每一行的标签是tr，行内数据是td,如果是第一行，那么可以使用th来进行加粗显示\n例如，以下表格\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;表格\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;table border=\u0026#34;1px\u0026#34; cellspacing=\u0026#34;0\u0026#34; width=\u0026#34;600px\u0026#34;\u0026gt; \u0026lt;!-- 表格的第一个头可以使用th --\u0026gt; \u0026lt;tr\u0026gt; 单元行 \u0026lt;th\u0026gt; 行内内容 序号 \u0026lt;/th\u0026gt; \u0026lt;th\u0026gt; 品牌logo \u0026lt;/th\u0026gt; \u0026lt;th\u0026gt; 品牌名称 \u0026lt;/th\u0026gt; \u0026lt;th\u0026gt; 企业名称 \u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 其样式结果如下\n可以把这个表格更加完善一下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;表格\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; td { text-align: center; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;table border=\u0026#34;1px\u0026#34; cellspacing=\u0026#34;0\u0026#34; width=\u0026#34;600px\u0026#34;\u0026gt; \u0026lt;!-- 表格的第一个头可以使用th --\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt; 序号 \u0026lt;/th\u0026gt; \u0026lt;th\u0026gt; 品牌logo \u0026lt;/th\u0026gt; \u0026lt;th\u0026gt; 品牌名称 \u0026lt;/th\u0026gt; \u0026lt;th\u0026gt; 企业名称 \u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; 1 \u0026lt;/td\u0026gt; \u0026lt;!-- logo --\u0026gt; \u0026lt;td\u0026gt; \u0026lt;img src=\u0026#34;../img/huawei.jpg\u0026#34; width=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; 华为 \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; 华为技术有限公司 \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; 2 \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;img src=\u0026#34;../img/alibaba.jpg\u0026#34; width=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; 阿里 \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; 阿里巴巴集团有限公司 \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 为了更加美观，我们可以给这个单元格加入居中效果\n1 2 3 4 5 \u0026lt;style\u0026gt; td { text-align: center; } \u0026lt;/style\u0026gt; 表单 表单是以form的形式开头，form里面有两个参数，一个是action，一个是method这两个参数，action指向的是提交的url，如果不指定，那么默认就是本机;method一个是get，另一个就是post方法，get会把提交的参数全部放到url里面，而post是直接以原始数据的形式进行提交。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=form, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;\u0026#34;, method=\u0026#34;get\u0026#34;\u0026gt; 用户名：\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;userName\u0026#34;\u0026gt; 年龄：\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;age\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 输入条和提交条都是以input标签的形式存在，需要显示使用type来指定他们的提交类型。\n总结 视频可以使用标签video来进行插入\n音频可以使用audio来进行插入\n正文是使用p标签来进行插入，在p包裹的标签内。同时可以使用text-indent来指定每一段的缩进尺寸\n表格是一种特殊的样式\n以table开始 每一行单元格可以使用tr来进行包裹 行中间，如果是第一行非数据元素，可以使用th(table head)来起到加大加粗剧中的样式 其它则可以使用td来进行包裹 表单是以form来进行书写的，action可以指向需要提交的url，method可以选择需要提交的方法。\n","date":"2025-02-28T15:20:43+08:00","permalink":"https://XiaoPeng0x3.github.io/p/html2/","title":"Html2"},{"content":"使用clash来加快访问 在国内想要访问github时比较麻烦，需要走代理，在使用git来push代码的时候可以使用clash的7890端口来走代理，在git中输入以下配置即可\nsocket5代理\n1 2 3 git config --global http.proxy \u0026#39;socks5://127.0.0.1:socks5端口号\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:socks5端口号\u0026#39; 端口号一般是7890\nhttp/https代理\n1 2 3 git config --global http.proxy \u0026#39;http://127.0.0.1:http端口号\u0026#39; git config --global https.proxy \u0026#39;https://127.0.0.1:https端口号\u0026#39; 在设置完后，可以ping一下github.com来尝试连通状况\n1 ping github.com ","date":"2025-02-28T14:53:50+08:00","permalink":"https://XiaoPeng0x3.github.io/p/push%E5%92%8Cpoll%E9%97%AE%E9%A2%98/","title":"Push和poll问题"},{"content":"html 通过复制新浪新闻页面来学习html的各种格式。\n快速入门 html的格式很简单，我们可以编辑一个简单的html文件来进行展示，在vscode里可以使用快捷键!来进行模板的生成，生成的代码如下\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 其中需要关注的是head和body这两个模块，我们可以先在body里面添加一些内容，例如Hello，World\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Hello, World \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 其结果如下\nhead里面的title标签就是网页的标签，所以我们可以把这标签修改为我们想要的内容，例如\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Hello, World \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 可以看到我们已经修改成功了\n现在我们来模拟一下新浪的新闻标题，新浪的标题结果如下\n我们来思考一下需要完成哪些任务\n新浪的图片标志 新浪\u0026gt;正文是一个超链接 中间的加粗加黑的大字标题 两条分割线 文字的样式 图片 我们需要插入一张图片，这张图片的路径可以是本地的路径，也可以是远程服务器上的路径，不过需要给出对应的url，图片的插入语法如下\n1 \u0026lt;img src:\u0026#34;url\u0026#34; /\u0026gt; 其中需要提供一个url来确定图片，除此之外，还可以调整图片的样式，比如图片的缩放程度。\n1 \u0026lt;img src:\u0026#34;\u0026#34; width=\u0026#34;xxx\u0026#34; height=\u0026#34;xxx\u0026#34; /\u0026gt; 假设我们把图片固定为300x300，那么需要指定好长宽比例\n1 \u0026lt;img src= \u0026#34;xxx\u0026#34; width=\u0026#34;300\u0026#34; height=\u0026#34;300\u0026#34; /\u0026gt; 为了还原，我们把页面设置为原始比例。后面我们先不设置超链接，所以只需要在图片的后面添加几行字即可，所以现在的代码变为\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务\u0026gt;正文 \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 大字标题 这种大字标题其实是\u0026lt;h\u0026gt; \u0026lt;/h\u0026gt;标签的作用，在html一共有6级标题可以设置，所以我们可以使用h1标题来设置。\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务\u0026gt;正文 \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 此时下方还有一个分割线，而分割线也是有专门对应的标签，即\u0026lt;hr/\u0026gt;(horizontal rule的缩写).现在我们的标题就变得和示例的标题一摸一样了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务 \u0026gt; 正文 \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;hr/\u0026gt; 2023年03月02日 21:50 央视网 \u0026lt;hr/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 样式 我们可以修改字体的颜色，例如，我们把标题的字体颜色修改为red，这里总共有三种方式：\n直接在行内标明颜色\n1 \u0026lt;h1 style=\u0026#34;color: red;\u0026#34;\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; 这样大标题就换了颜色\n内嵌样式\n直接在\u0026lt;head\u0026gt;里面添加一个style样式，然后指定标签的名称，把对应的样式填进去即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; 把整体样式填写在这里 \u0026lt;style\u0026gt; h1 { color: blue; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务 \u0026gt; 正文 \u0026lt;!-- \u0026lt;h1 style=\u0026#34;color: red;\u0026#34;\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; --\u0026gt; \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;hr/\u0026gt; 2023年03月02日 21:50 央视网 \u0026lt;hr/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意，这样做会装饰所有\u0026lt;h1\u0026gt;包裹的字体，一个优点是，如果需要统一某些共同的样式，那么这样可以快速的统一一些样式。\n外联样式\n把这些样式专门封装为.css，然后使用link把该样式链接进来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;!-- \u0026lt;style\u0026gt; h1 { color: blue; } \u0026lt;/style\u0026gt; --\u0026gt; 外联样式 \u0026lt;link rel=\u0026#34;style\u0026#34; href=\u0026#34;../css/news.css\u0026#34;/\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务 \u0026gt; 正文 \u0026lt;!-- \u0026lt;h1 style=\u0026#34;color: red;\u0026#34;\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; --\u0026gt; \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt; 变成了蓝色\u0026lt;/h1\u0026gt; \u0026lt;hr/\u0026gt; 2023年03月02日 21:50 央视网 \u0026lt;hr/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; rel：是 \u0026ldquo;relationship\u0026rdquo; 的缩写，表示“关系”。href：是 \u0026ldquo;hypertext reference\u0026rdquo; 的缩写，表示“超文本引用”，即资源的地址或链接。\n总结，当需要重复引用一个样式时，外联样式可能是最好的选择。\n分块样式 当多个内容处于一行的时候，我们可以使用分块的标签来对其进行修饰。\n\u0026lt;span\u0026gt;选择器是一个空白标签，被这个标签包裹的内容在默认情况下不会作出任何修改，但是还是可以凭借这个标签来进行样式的修改，同样的，可以作用在\u0026lt;span\u0026gt;上的修饰也有三种\n直接修饰\n元素选择器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; 专门进行修饰 span { color: red; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务 \u0026gt; 正文 \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;span\u0026gt;2023年03月02日\u0026lt;/span\u0026gt; 21:50 央视网 \u0026lt;hr/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 类选择器\n可以在style中指定类选择器,需要我们给这个类起一个名字，例如，我们想要修饰时间，把所有时间字体全部修改为蓝色，那么我们就可以这样写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;!-- \u0026lt;style\u0026gt; h1 { color: blue; } \u0026lt;/style\u0026gt; --\u0026gt; \u0026lt;link rel=\u0026#34;style\u0026#34; href=\u0026#34;../css/news.css\u0026#34;/\u0026gt; \u0026lt;style\u0026gt; span { color: red; } .time { color: blue; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务 \u0026gt; 正文 \u0026lt;!-- \u0026lt;h1 style=\u0026#34;color: red;\u0026#34;\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; --\u0026gt; \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;span class=\u0026#34;time\u0026#34;\u0026gt;2023年03月02日\u0026lt;/span\u0026gt; \u0026lt;span\u0026gt; 21:50 央视网 \u0026lt;/span\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 在标签里面定义好class，然后在head的style里面使用.classname来进行修饰。值得一提的是，在span和class同时都被修饰的情况下，class的优先级更好\n使用id来进行修饰\n同样的，要想使用id，可以使用#开头来进行修饰，需要注意的是,id是唯一的，不可以重复使用，如果要重复使用，那么可以使用类装饰器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;焦点访谈：中国底气 新思想夯实大国粮仓\u0026lt;/title\u0026gt; \u0026lt;!-- \u0026lt;style\u0026gt; h1 { color: blue; } \u0026lt;/style\u0026gt; --\u0026gt; \u0026lt;link rel=\u0026#34;style\u0026#34; href=\u0026#34;../css/news.css\u0026#34;/\u0026gt; \u0026lt;style\u0026gt; span { color: red; } .time { color: blue; } #f { color: #00ff00; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;../img/news_logo.png\u0026#34; /\u0026gt; 新浪政务 \u0026gt; 正文 \u0026lt;!-- \u0026lt;h1 style=\u0026#34;color: red;\u0026#34;\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; --\u0026gt; \u0026lt;h1\u0026gt; 焦点访谈：中国底气 新思想夯实大国粮仓 \u0026lt;/h1\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;span class=\u0026#34;time\u0026#34;\u0026gt; 2023年03月02日 21:50 \u0026lt;/span\u0026gt; \u0026lt;span id=\u0026#34;f\u0026#34;\u0026gt; 央视网 \u0026lt;/span\u0026gt; \u0026lt;hr/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 超链接 超链接的标签是a，在使用时，我们只需要把超链接标签包裹住对应的文字即可\n1 2 3 4 5 \u0026lt;span id=\u0026#34;f\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;baidu.com\u0026#34;\u0026gt; 央视网 \u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; 这样就可以把央视网指向对应的链接处，不过这样默认是链接的形式，所以可以设置css样式来取消下划线。\n在style里面为所有的a标签来指定样式\n1 2 3 4 a { color: black; text-decoration: none; /* 设置文本为一个标准的文本 */ } 总结 图片的插入\n1 \u0026lt;img src=\u0026#34;\u0026#34; /\u0026gt; 标题\n1 2 3 4 5 6 7 \u0026lt;h1\u0026gt; \u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt; \u0026lt;/h2\u0026gt; 一直到h6\ncss样式\n这里样式比较多，需要了解\n直接使用标签\n类装饰器，前面要加“.\u0026quot;\nid装饰器，前面加\u0026quot;#\u0026quot;,每个标签使用的id是唯一的\n可以连接外部css样式\n1 \u0026lt;link rel=\u0026#34;xxx\u0026#34; href=\u0026#34;xxx\u0026#34;/\u0026gt; 超链接\n超链接的标签是\u0026lt;a href= \u0026quot;\u0026quot;\u0026gt; \u0026lt;/a\u0026gt;，凡是这样的标签都可以在style里面进行修饰，超链接也不例外\n","date":"2025-02-27T17:27:54+08:00","permalink":"https://XiaoPeng0x3.github.io/p/html-day01/","title":"Html-day01"},{"content":"多线程 创建启动一个线程 创建一个线程大概分为下面几步\n自定义线程类继承Thread类 重写run方法，编写线程执行体 创建线程对象，调用start方法启动线程 在继承Thread类时，首先要重写run方法，即把需要在多线程里面实现的逻辑写到run方法中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class MyThread extends Thread{ @Override public void run() { // run方法 for (int i = 0; i \u0026lt; 20; i++) { System.out.println(\u0026#34;我在看代码！\u0026#34;); } } public static void main(String[] args) { // main线程 // 创建一个线程 MyThread mt = new MyThread(); // 调用start来开启线程 mt.start(); // 程序还是串行执行的 mt.run(); for (int i = 0; i \u0026lt; 20; i++) { System.out.println(\u0026#34;主线程\u0026#34;); } } } 与run方法不同的是，start方法会额外开启一个新的线程来执行run方法里面的逻辑，而调用run缺不会额外开启一个新的线程。\n多线程下载器 把一些业务逻辑放在run方法里面，我们就可以使用多线程来进行一些业务逻辑处理。\n首先构建好一个下载器\n1 2 3 4 5 6 7 8 9 class DownLoad{ public void downloader(String url, String name) { // 使用一个FileUtils包来进行书写 try{ FileUtils.copyURLToFile(new URL(url), new File(name)); }catch(IOExpection e) throw new RuntimeException(e); } } 构建好下载器后就可以启动线程这些资源\n还是三要素\n继承Thread 重写run方法 在main线程中new Thread对象，调用start方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class TestThread extends Thread { // 定义好name String name; String url; public TestThread(String name, String url) { // xxxx } public void run() { // 重写run函数 // 使用下载器下载 DownLoader d = new DownLoader(); d.downloader(url, name); } public static void main(String[] args) { // 创建线程 TestThread t1 = new TestThread(xxx, xxx); TestThread t2 = new TestThread(xxx, xxx); // 启动start t1.start(); t2.start(); } } 这样就可以下载好图片。\n","date":"2025-02-26T20:08:05+08:00","permalink":"https://XiaoPeng0x3.github.io/p/thread%E7%B1%BB/","title":"Thread类"},{"content":"Quick Start 在安装后Pytorch之后，官方提供了一个基于FashionMNIST的分类任务，通过此任务可以让我们快速入门怎么样使用数据集去训练一个神经网络模型\n数据集加载 torchvision中集成了datasets的API以便于快速的下载一些常用的数据集\n1 2 from torchvision import datasets from torchvision.transforms import ToTensor 使用datasets\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Download training data from open datasets. train_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, train=True, download=True, transform=ToTensor(), ) # Download test data from open datasets. test_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, train=False, download=True, transform=ToTensor(), ) root是存储下载数据集的路径。ToTensor是把原始数据集转换为Pytorch的张量，一般来说，对于一张原始图片，其shape就是[H, W, C]，在Pytorch中，为了方便计算，通常在ToTensor后会把其shape转换为[C, H, W]的形状。\n加载数据集 在Pytorch中，加载数据集都是使用DataLoader类来进行加载，返回的是一个类似于迭代器的数据类型，值得注意的是，我们也可以自行构建一个自己的数据集来进行数据加载，而且这个数据集必须是Dataset类的子类。\n1 from torch.utils.data import DataLoader DataLoader的第一个参数类型就是Dataset类\n1 train_dataloader = DataLoader(train_data, shuffle= True, batch_size= 64) 后面就是一些必选参数，像shuffle, batch_size这些需要自己选择，一般来说，在训练集需要打开shuffle来进行训练，而测试集不需要随机打乱。batch_size就是每一次选择几张图片作为一个batch来进行训练，batch_size选择的越大，占用的内存也就越高。\n1 test_dataloader = DataLoader(test_data, shuffle=True, batch_size= 64) 加载之后，输入的数据应该有四个维度，即[B, C, H, W]，对于FashionMNIST来说，其数据维度就是[64, 1, 28, 28]，我们可以来验证一下\n1 2 3 4 for X, y in test_dataloader: print(f\u0026#34;Shape of X [N, C, H, W]: {X.shape}\u0026#34;) print(f\u0026#34;Shape of y: {y.shape} {y.dtype}\u0026#34;) break 选择损失函数和优化器 对于多分类问题，可以选择交叉熵损失函数即\n1 loss_func = nn.CrossEntropyLoss() 同样的，我们也可以选择不同的优化方法，例如SGD，SGD+Momentum，Adam等等这些损失器\n1 optim = torch.optim.Adam(model.parameters(), lr=0.001) 模型的训练 开始训练模型，可以把模型的训练封装为一个函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def train(dataloader, model, loss_func, optimizer): # 获取总的数据个数 size = len(dataloader.dataset) # 开启训练模式 model.train() for batch, (x, y) in enumerate(dataloader): X, y = X.to(device), y.to(device) # 通过model来获取pred_y pred = model(X) # 损失函数 loss = loss_func(pred, y) # 反向传播 loss.backward() # 更新参数 optimizer.step() # 梯度归零 optimizer.zero_grad() # 每100个batch得到一个输出 if batch % 100 == 0: loss, current = loss.item(), (batch + 1) * len(X) print(f\u0026#39;loss: {loss:\u0026gt;7f} [{current:\u0026gt;5d} / {size:\u0026gt;5d}]\u0026#39;) 测试阶段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def test(dataloader, model, loss_fn): # 获取总的样本个数 size = len(dataloader.dataset) # 获取批次数 num_batches = len(dataloader) # 开启评估模式 model.eval() test_loss, correct = 0, 0 with torch.no_grad(): for X, y in dataloader: X, y = X.to(device), y.to(device) pred = model(X) # 获取验证集上的损失 test_loss += loss_fn(pred, y).item() # 正确的样本率 # argmax(1) 与 真值是否相等 correct += (pred.argmax(dim=1) == y).sum().item() # 获取测试集上的损失值 test_loss /= num_batches ","date":"2025-01-03T16:29:50+08:00","permalink":"https://XiaoPeng0x3.github.io/p/quick_start/","title":"Quick_start"},{"content":"学习率 学习率是一个很重要的参数，而且学习率决定了网络能否快速的收敛并趋于稳定。目前为止，我们接触到的网络实际上都是一个优化问题，即如何找到损失函数的极小值。对于多元函数使用的就是梯度下降法去找到极小值，其中又有很多梯度下降的优化版本，例如sgd + momentum、adam等方法，这些方法里面都要用到学习率这个参数\n老师给出了许多学习率的选择方法\nstep 学习率 step学习率的思路就是每经过给定的几个epochs，就重新设置学习率。可以这样做是因为在学习初期，即使学习率很大也没有关系，大的学习率反而可以减少训练时间，当经过几轮epoch后，把学习率降低可以减少模型的震荡，从而提高精度。\ncos 学习率 在训练过程中，学习率的参数变化是cos型的\n线性下降学习率 学习率的选择是线性的\n平方根学习率 这个图片是反平方根的函数曲线\u0026hellip;.\n超参数选择 选择超参数（hyperparameter）是深度学习和机器学习中关键的步骤，影响模型的性能和训练效率。\n1. 检查初始损失 (Check initial loss)\n目的：确认模型和数据管道是否正确配置。 细节 使用默认或初始超参数（如随机初始化权重，标准学习率）。 检查初始损失是否异常高或为NaN。 如果损失值异常，可能是数据预处理或模型设置的问题。 2. 在小样本上过拟合 (Overfit a small sample)\n目的：验证模型是否有能力拟合数据（模型复杂度是否足够）。 细节 使用数据集中的一小部分样本（例如5-10个）。 调整模型直到它能够完全拟合这组数据，损失降到接近零。 如果无法过拟合，检查模型架构或超参数（如学习率、网络深度等）。 3. 找到能使损失下降的学习率 (Find LR that makes loss go down)\n目的：找到一个合适的学习率，使损失能稳步下降。 细节 采用 learning rate finder 技术。 逐步增加学习率，绘制损失随学习率变化的曲线。 选择损失开始明显下降但未发生震荡的学习率（通常在曲线的下降初期）。 4. 粗略网格搜索，训练1-5个epoch (Coarse grid, train for ~1-5 epochs)\n目的：快速筛选出表现较好的超参数范围。 细节 在关键超参数（如学习率、权重衰减、batch size）上进行粗粒度的网格搜索。 每次试验只训练1到5个epoch，足够观察趋势但不过多浪费计算资源。 排除性能较差的参数组合。 5. 精细网格搜索，延长训练时间 (Refine grid, train longer)\n目的：进一步优化超参数，找到最佳的参数组合。\n细节\n缩小关键超参数的搜索范围，进行更精细的网格搜索。 增加训练epoch（例如10到50个）以评估长期性能。 检查模型在验证集上的表现以避免过拟合。 6. 检查学习曲线 (Look at learning curves)\n目的：通过学习曲线分析模型的训练动态。\n细节\n学习曲线显示训练和验证损失或精度随时间变化的趋势。\n常见问题及解决办法\n如果验证损失明显高于训练损失：模型可能过拟合，需要正则化或增加数据。 如果两者都较高：可能是学习率太低或模型复杂度不足。 如果训练损失震荡：可能是学习率过高或模型过于复杂。 这也是老师在课上提到的这几点，为了方便查看训练的进展，一个很好的习惯是把模型在测试集上的精确度和验证集上的精确度给可视化，老师这里提到了一些有用的建议。\nloss一开始不降低\n你的初始化很bad!\nloss很高而且随着训练的进行不发生变化\n学习率太大了，试试学习率衰减的办法吧！\n衰减的太早了，导致不能快速下降\n准确率依旧在上升，应该训练更长的时间\n这种情况也是很常见的，即数据在训练集上精度很高，但是在测试集上精度却不增高，这是因为发生了过拟合，导致模型只能很好的识别出“见到”过的数据\n训练集与验证集之间精度在训练过程中相差很小，假设数据来源可靠的话，那么说明模型还不够复杂，或者模型还是处于欠拟合的状态\n总结 在这一部分，我们只介绍了学习率以及超参数选择的一些技巧，后面的内容与迁移学习以后再做总结！\n","date":"2024-12-07T12:30:58+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cpart2/","title":"训练神经网络part2"},{"content":"前言 神经网络一个非常关键的地方就在于如何能够更快、更精确的求解出各种参数，这些参数一般是在学习的过程中可以得到，而有一些参数却需要人为的根据经验来进行初始化，例如学习率的大小、每次训练时batch size的大小、损失函数的选择以及激活函数的选择。下面来记录一下如何选择这些参数\n激活函数 激活函数在神经网络起到的是引入非线性的作用，当我们不选择激活函数的时候，实际上并没有增加有效层的层数，而激活函数又有很多种选择，早期的激活函数有sigmoid、tanh函数，而我们用的较多的有ReLu以及ReLu的变体\n类sigmoid函数 sigmoid函数在早期十分受欢迎，函数的值域在[0,1]中，这个函数在早期受欢迎的原因是它很好的模拟了神经元接受刺激产生冲动的一个过程，但是在实践中它有着很多的缺点\n饱和区 当x的取值变得很大或者很小时，其值趋近于1或者0，从图中可以近似估计一下，可以看到输出$\\sigma(x)$对于x的梯度近似为0，那么在使用反向传播链式求导时，很容易将上游梯度的结果变为一个非常小的值，也就是所谓的kill gradients，导致梯度不能通过反向传播而传递至前一层。\nNot zero centered 从图中看出，sigmoid函数不是关于原点分布的，这就会导致在计算参数W的梯度依赖于上一层的梯度，例如，给定两个参数W1和W2，对于输出来说 $$ f = X_1W_1 + X_2W_2 $$ 可以使用链式法则求得这两个参数的梯度 $$ \\frac{dL}{dW_i} = \\frac{dL}{df} \\frac{df}{dW_i} $$ 也就是 $$ \\frac{dL}{dW_i} = \\frac{dL}{df} X_i $$ 而因为$X_i$恒为正(来自sigmoid的输出)，所以$\\frac{dL}{dW_i}$的符号只取决于上游梯度，那么对于$W_1和W_2$这两个梯度来说，其符号要么同时为正，要么同时为负，所以从图上看就是这样的\n这就使得网络很难训练\n计算代价高 显然，指数级别的计算代价要明显高于一般运算\ntanh 这里也介绍了tanh函数，从图像上来说，与sigmoid相比，tanh只是少了not-zero-centered这个缺点\n类ReLu ReLu的激活函数是 $$ ReLu(x) = max(0, x) $$ 选择这个激活函数也是AlexNet一个创新点之一，与之前的类sigmoid函数相比，ReLu简单、收敛快、不存在饱和梯度，但是这个函数也是not zero centered，而且也有着其它的缺点\ndead ReLu 当输入X小于0时，ReLu只是简单的去把X设置为0，导致小于0的部分的梯度永远也不会去更新，当输入 $x≤0$，输出总是 0。因此，如果一个神经元的输入权重和偏置的组合导致它始终进入负区,该神经元在整个训练过程中都不会被激活，也不会对学习产生贡献。也就是该神经元是dead的，并不会增强模型的能力。\n为解决这个问题，研究人员又提出了ReLu的变体\nLeaky ReLu Leaky ReLu的思路是小于0的部分不是简单的设置为0，而是设置为一个很小很小的数\n把设置的这个很小的数叫做$\\alpha$，在反向传播中可以学习这个参数\n还有其它的各种变种\n总结 规则怪谈：\n当你不知道使用什么激活函数，或者真的不在乎那0.1%的精度提升，直接选择ReLu 当你需要极值的优化，那么可以尝试一下ReLu的变体 不要使用tanh和sigmoid 数据处理 对数据进行预处理可以更好的训练网络。\n下图是一个对原始数据进行0-1正态分布的处理过程\n这里有一个值得注意的代码细节\n1 2 X -= np.mean(X, axis=0) X /= np.std(X, axis=0) 这里对数据进行处理都是在同一类的数据进行处理，而在数据集里面按照一般约定，每一列是一个类的所有数据分布，所以这里是在axis=0(torch里面使用的是dim)上进行数据处理。\n对数据进行预处理可以使得在反向传播时更容易求解梯度和传播梯度\n对于图像来说，可以减去图片的均值、减去每个通道上的均值以及在每个通道上做正态分布初始化\n权重参数初始化 到目前为止，权重参数W一直是一个非常重要的参数，而且权重的初始化也是训练网络很重要的一部分，一个想法是，假设我们有着一个比较简单的网络，如果我们把权重参数全部初始化为0\n1 W = torch.zeros(N, D) 那么在前向传播的过程中，每一层的输入就都是0，那么这个网络实际上什么都做不了，一个比较常见的做法是把W按照高斯分布进行初始化\n1 W = torch.randn(N, D) * weight_scale 例如，weight_scale可以初始化为0.01\n1 W = torch.randn(N, D) * 0.01 这样初始化在网络层数比较小的时候没什么问题，但当网络层数非常多时，后面层获得的输入就会非常非常小，以至于无法表示\nXavier 初始化 对于激活函数是tanh时，xavier激活函数可以很好的结果这个问题，这个方法的核心思想在于把输入和输出的分布尽可能相似，也就是输入的方差与输出的方差一致。\n对于输出来说 $$ y_i = \\sum_{i = 0} ^ D X_iW_i $$ 为了使两者方差相等，即 $$ Var(y_i) = \\sum_{i=0} ^ D Var(X_iW_i) $$ 因为输入X的方差是1，即 $$ Var(y_i) = D*Var(W_i) $$ 所以$W_i$的方差就是原来的$\\frac{1}{D}$,只需要在原来初始化时除以输入维度数即可\n1 W = torch.randn(Din, Dout) / torch.sqrt(D) # 注意这里是方差 kaiming初始化 也叫做He初始化，这个初始化方法是专门为ReLu实现的，回想一下ReLu函数，在ReLu函数作用下，对于0-1分布来说，每次产生非0的概率就是0.5,所以对于这组数据来说，每次方差都要缩小一半。\n同样的，为了使输入和输出的分布近似相等，所以可以推导出在ReLu函数作用下的初始为\n1 W = torch.randn(Din, Dout) / torch.sqrt(2 / Din) 同样的，对于ResNet来说，整个初始化就是这样的\n这样可以保证在两个卷积层输出后方差不变。\n正则化 正则化技术是防止模型过拟合的一个关键技术，正则化可以从某种程度上减少模型的复杂度。\n在一开始，对于损失函数，我们讨论了L1正则化和L2正则化这两种简单有效的正则化方法\n此外老师还介绍了一种正则化方法DropOut,DropOut一般用于全连接层的优化，对于一些神经元的输出，DropOut会按照P的概率把这些神经元的输出置为0，其结果就像是在复杂的网络中选择一些简单的子网络\n一样，从而降低模型的复杂度。\n为了保证这两个模型依旧是等价的，我们把未丢弃的那些值都除以p，这样可以保证在DropOut前后两者均值相同。\n数据增广 数据增广的想法可能是更好的去模拟人类的思维，对于一张图片来说，我们可以对这张图片进行裁剪、旋转、增强亮度等操作，对于人类来说，即使经过这些操作，也还是很容易就可以辨别出这是同一张图片，这恰恰也是我们对机器也可以实现的能力。\n除此之外，在数据集较小、数据集图片质量不佳时，我们就可以人为的对数据进行一些操作，从而达到训练要求。\n总结 这次老师分享了一些训练网络时的一些技巧，包括激活函数的选择、数据预处理的重要性、权重参数初始化的方法、正则化以及数据增广的办法，这些都会在作业中用到！\n","date":"2024-12-07T12:30:50+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cpart1/","title":"训练神经网络part1"},{"content":"前言 全连接神经网络面临的问题 在此之前，我们一直是在全连接层神经网络进行讨论，全连接神经网络其实也有许多不便之处\n无法理解图像模板\n对于之前的所有的有关图像分类实现的任务，对于给定的图片(size:3x32x32)，我们并不考虑图片整体或者图片的一些局部特征是什么样的，而是直接把3x32x32的图片展平为一个一维向量(1x3072)，然后经过一些矩阵乘法，我们就可以得到这个图片的scores\n内存问题\n3072维的向量似乎还是可以接受的，但是实际上这个图片是非常小的，假设我们使用了一些比较大的图片，那么输入的维度肯定会显著的提升。在进行神经网络全连接后，显然，每一层上都有着巨量的计算，而且为了有更好更复杂的模型，神经网络的层数也会增加，那么在此产生的计算和内存消耗将是巨大的\n卷积神经网络 卷积层 卷积神经网络的思路与全连接不同，卷积神经网络更加“尊重”图像的样子，它不会把输入图像进行压缩，而是在乎图像的整体特征，而保留整体特征的一个关键部分就是卷积核\n卷积核 卷积核可以保留提取一些图片中相似的特征，只要你了解卷积核是怎么提取图片的特征的，你就会明白为什么\n卷积核的计算\n卷积核会在原来输入图片的维度上进行计算，假设我们使用的卷积核是3x5x5的\n对于图像中每个5x5的部分，我们使用点积去进行计算\n多个卷积核的使用\n在经过卷积核的计算后，我们得到了一个1x28x28的输出(计算公式后文给出)，更一般的，我们会使用多个卷积核进行卷积，此时卷积核的维度就是Nx3x5x5，那么输出就会是Nx28x28的\n更一般的，对于一批数据，我们会对着一批数据进行卷积操作，此时就变为\n下面是其公式表达形式\n卷积层的堆叠\n为了搭建更加复杂的网络，通常会堆积多个卷积层(像之前两层网络一样，在一定范围内层数越多越复杂，能力越高)，此时注意，为了确保引入多个卷积层而不是只是一个卷积层，这里也引入了非线性激活函数(ReLu)\n输出大小 卷积的过程就是在原始图片上进行滑动相乘的结果，当使用5x5的卷积核时，输入图片大小为32x32，那么在输入的长上的最后一次运算就是第28, 29, 30, 31 ,32的格子上；同样对于宽也是一样的，这样就可以得到输出图像的特征就是28x28\n更一般的，对于输入特征W来说，我们使用大小为K的卷积核进行运算，那么输出特征就是**W-K+1**的，利用这个公式，我们就可以很方便的计算输入特征为32x32时，卷积核大小为5x5时的输出特征。\n带来的新问题 经过5x5的卷积核运算后，一个肉眼可见的差别就是输出图像与原始输入图像维数是不同的，当我们使用很多个卷积核后，输出的图像看起来像是降维一样。\n为了保持输出图像与输入图像的维度(可能是减少损失的信息)，我们可以使用填充输入图像的方式来保证维度。\n需要填充0的层数p就是(k-1)/2，经过填充，输出的图像大小与输入就有着相同的维度。\n不同的步长 在上面卷积核进行计算的时候，我们都是默认每次卷积的时候都是挨个滑动，事实上滑动的时候也可以跳跃着滑动，也就是说，在原先的基础上，如果每次都是N步去滑动卷积，那么输出的维度就会减小N倍，这个时候我们可以更新我们的计算公式\n池化层 池化分为平均池化层和最大池化层，例如，当使用大小为2x2的卷积核进行最大池化的时候，实际上就是对卷积后的每层输出进行特征筛选\n上图是一个使用最大层池化，步长为2的池化层，因为步长的原因，池化后的图片大小会发生变化，使用平均池化也是一样的原理，只需要计算2x2内的均值即可\n前向传播 对于给定的数据，怎么实现前线传播的计算呢？假设下面是给定的数据\nx, 大小为NxCxHxW，N代表这一批的数据，C表示图片的通道数，HxW是图片的大小 w，大小为FxCxHHxWW，有F个卷积核，每个卷积核大小都是CxHHxWW b，大小为哦F，表示偏执 现在思考怎么计算经过卷积后的数据out\n卷积的过程 首先，我们可以拿出一张图片来进行举例，那么这张图片就是x[i, :, :, :],同时，我们也拿出一个卷积核w[i, :, :, :]。回想一下老师在课堂上举过的例子\n这个输出是怎么得到的呢？因为图片是三通道的，所以在每一个通道上都要进行卷积操作，实际上得到的最后输出就是三通道上的总和，那么，对于图片来说，其计算过程就是这样的\n1 2 3 4 5 6 7 Hout, Wout = out.shape # 得到输出的size # 假设步长是stride for i in range(Hout): for j in range(Wout): # 这里假设输出和x有着同样size # 三个通道的总和 output[i, j] = (x[:, i:i+k, j:j+k] * w).sum() + b 更一般的，当我们可以进行推广\n1 2 3 4 5 6 7 8 9 10 11 # 输出图片的维度与步长stride和输入的填充有关 N,C,H,W = x.shape F,C,HH,WW = w.shape H_out = 1 + (H + 2 * pad - HH) // stride W_out = 1 + (W + 2 * pad - WW) // stride for n in range(N): for f in range(F): for i in range(H_out): for j in range(W_out): # 计算第n个数据在第f个卷积核上的输出 out[n, f, i, j] = (x[n, :, i, j] * w[f]).sum() + b[f] # 三通道相乘的和 反向传播求梯度 反向传播求梯度这里其实有点绕，假设我们已经知道损失函数对于输出的梯度dout，那么我们就可以使用链式法则进行求导\nout[0, 0, :, :]代表着第1个图片在第一个卷积核上的输出，我们来分析一下它是由哪些部分计算得到的 $$ out[0, 0, :, :] = x[0, 0, :, :] * w[0, 0, :, :] + x[0, 1, :, :] * w[0, 1, :, :] + x[0, 2, :, :] * w[0, 2, :, :] + bias[0] $$ 现在把卷积核的个数拓展到F个，那么求第f个卷积核的输出就是 $$ out[0, f, :, :] = x[0, 0, :, :] * w[f, 0, :, :] + x[0, 1, :, :] * w[f, 1, :, :] + x[0, 2, :, :] * w[f, 2, :, :] + bias[f] $$ 转换为代码就是\n1 out[0, f, :, :] = np.sum(x[0, :, :, :] * w[f, :, :, :], axis=0) + bias[f] 需要注意的是，要考虑的是，我们需要学习的参数在哪里参与运算，分层求解其梯度即可。\n正则化技术 当网络变得很深的时候，网络通常会变得难以训练，这是因为在我们依赖的方法上的缺点，对于一个很深的网络来说，当前层的梯度来自与损失函数对参数的梯度，而梯度在流动的时候又是依赖于链式法则和反向传播，因此，假设上游梯度：\n所有的梯度都是小于1的数\n那么在反向传播相乘的时候，很有可能出现梯度消失，即数值过小(nan)\n当梯度全部都是大于1的数\n那么在反向传播的过程中，多个大于1的数也会导致数值过大而溢出\n正则化的作用 why it works?，正则化就是调整数据之间的分布，例如，假设 $$ Y = X_1W_1 + X_2W_2 $$ 而不幸的是，X1可能是一些房屋面积的数据，例如100平米，150平米，而X2有可能是附近的医院个数，例如10,15，显然，两者数据差别有点大，我们可以假设损失函数对于各个数据之间的梯度图，例如\n其中X1是数值比较大的数，X2是数值比较小的数，中间的星号就是损失函数最小时X1和X2的取值，可以看到，整个图像的分布就像是一个椭圆形数据，对于X1来说，每次的变化值都要大于X2的变化值，这就导致了每次在梯度下降的时候，很有可能导致下降时候的振荡和无法收敛。\n使用正则化之后，可以把数据进行归一化操作，这样对于整个数据分布来说，其形状会更加接近于圆型，这样在梯度下降的时候，对于一些参数learning_rate就可以调整的比较大，同时也可以加快模型的收敛，减少训练时间。\n同时，这里的正则化技术有很多，例如batch normalization, layer normalization, xxx normalization，感兴趣的可以自行查阅\n批正则化处理的技术一般放在全连接层之后或者卷积层之后，而且是放在非线性激活函数之前\n总结 卷积神经网络的组成一般包括：卷积层、池化层和全连接层，其中每个层里面又有各种各样的细节，下次来看一看怎么更好的训练一个网络\n","date":"2024-11-25T17:12:53+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","title":"卷积神经网络"},{"content":"前言 这个问题似乎是之前没有接触到过的问题，题目的大概意思就是，给定一个数组，数组中可能会有重复的元素，现在我们的任务是\n调整元素，使得区间内没有重复的元素 调整后的区间和最大 贪心算法 例如， 一个数组是\narr = [1,2,3,4,5,5,6]\n怎样调整使得数组和最大且元素不重复呢？\n贪心的思路 从贪心思路出发， 只要每个元素都是最大的， 那么整体和就是最大的，所以，我们不去调整最大值，而是保留下来数组里面的最大值\n解题 先将数组进行排序\n1 arr.sort(reverse= True) 然后开始考虑挨个调整\n将当前元素与该元素前面一个元素进行比较\n因为有重复的元素，所以要考虑最大值有重复的情况\n例如\n1 arr = [6,6,6,5] arr[i]来说， 为了调整最大， 那么我们就需要将arr[i]和arr[i-1]-1做比较， 取这两个值之间的最小值\n如果与arr[i] = arr[i-1], 那么我们就可以把arr[i]调整为在贪心策略下的最大值 如果不相等，因为我们是经过排序的， 所以这个值的本身就是可以取到的最大值 例题 LeetcCode945.使数组唯一的最小增量\n给你一个整数数组 nums 。每次 move 操作将会选择任意一个满足 0 \u0026lt;= i \u0026lt; nums.length 的下标 i，并将 nums[i] 递增 1。\n返回使 nums 中的每个值都变成唯一的所需要的最少操作次数。\nLeetcode 1647. 字符频次唯一的最小删除次数\n如果字符串 s 中 不存在 两个不同字符 频次 相同的情况，就称 s 是 优质字符串 。\n给你一个字符串 s，返回使 s 成为 优质字符串 需要删除的 最小 字符数。\n字符串中字符的 频次 是该字符在字符串中的出现次数。例如，在字符串 \u0026quot;aab\u0026quot; 中，'a' 的频次是 2，而 'b' 的频次是 1 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution: def minDeletions(self, s: str) -\u0026gt; int: # 从大到小排序 # arr[i-1] = min(arr[i-1], arr[i]-1) temp = [0] * 26 for c in s: temp[ord(c)-ord(\u0026#39;a\u0026#39;)] += 1 # 排序 temp.sort(reverse=True) ans = 0 for i in range(1, len(temp)): a = temp[i] temp[i] = min(temp[i-1]-1, temp[i]) if temp[i] \u0026lt;= 0: temp[i] = 0 ans += a - temp[i] return ans ","date":"2024-11-24T17:24:18+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E5%8C%BA%E9%97%B4%E5%92%8C%E6%9C%80%E5%A4%A7%E4%B8%94%E5%85%83%E7%B4%A0%E4%B8%8D%E9%87%8D%E5%A4%8D/","title":"区间和最大且元素不重复"},{"content":"前言 前面讲解了一些优化算法，尤其是各种梯度下降算法，这次来看一看神经网络\n神经网络 神经网络的特点 前面我们在学习线性分类器的时候了解到，线性分类器对于异或、圆形、半圆形数据不能很好的划分出一条边界，这也导致了线性分类器不是那么的有效，而神经网络可以解决这个问题。\n一般的，神经网络可以划分为输入层、隐藏层、输出层这三种结构，而正是隐藏层的一些非线性特征使得神经网络可以拟合出各种决策边界，所以在线性分类器上解决不了的问题便可以使用神经网络很好的解决。\n为了简单起见，作业里面实现的是一个两层的神经网络，使用的激活函数是Relu激活函数\n得分方式的改变 在之前的线性分类中，我们把 $ X^T W $看作是一个得分的输出。在神经网络里面这里的计算方式也与其计算方式相同，不同的是，在多层神经网络之间传递上一层的分数时，总是要经过非线性激活函数输出后把分数传递到下一层，这是因为如果不加激活函数，那么实际上我们在做乘法的时候还是取得是一个线性计算的过程，所以要加上激活函数，从而引入非线性。\n全连接神经网络也叫做多层感知机\n因此，计算得分的方式可能会是\n1 2 3 4 5 6 7 import numpy as np h1 = X.dot(W1) # 得到第一层的分数 # 执行Relu, 即 h1 = max(0, h1), 只保留大于0的部分 h1[h1 \u0026lt; 0] = 0 # 经过激活函数后输出到下一层 scores = h1.dot(W2) # 得到分数 上文已提到，不加激活函数实际上做的还是线性变换\n可以看到，经过合并后，不加激活函数的结果等价于一个线性分类\n激活函数 激活函数的存在就是为了引入非线性，从而可以划分出非线性的决策边界，下面是一些激活函数\n简单的实现 ppt中给出了一个简单的使用MSE作为损失函数的两层神经网络\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import numpy as np # N是训练的batch size; D_in 是input输入数据的维度; # H是隐藏层的节点数; D_out 输出的维度，即输出节点数. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建输入、输出数据 x = np.random.randn(N, D_in) #（64，1000） y = np.random.randn(N, D_out) #（64，10）可以看成是一个10分类问题 # 权值初始化 w1 = np.random.randn(D_in, H) #(1000,100),即输入层到隐藏层的权重 w2 = np.random.randn(H, D_out) #(100,10),即隐藏层到输出层的权重 learning_rate = 1e-6 #学习率 for t in range(500): # 第一步：数据的前向传播，计算预测值p_pred h = x.dot(w1) h_relu = np.maximum(h, 0) y_pred = h_relu.dot(w2) # 第二步：计算计算预测值p_pred与真实值的误差 loss = np.square(y_pred - y).sum() print(t, loss) # 第三步：反向传播误差，更新两个权值矩阵 grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.T.dot(grad_y_pred) grad_h_relu = grad_y_pred.dot(w2.T) grad_h = grad_h_relu.copy() grad_h[h \u0026lt; 0] = 0 grad_w1 = x.T.dot(grad_h) # 梯度下降法 w1 -= learning_rate * grad_w1 w2 -= learning_rate * grad_w2 这里比较有意思的地方是如何去更新我们的权重矩阵W1,W2\n反向传播 求得W1和W2得梯度便可以使用梯度下降法去进行跟新，那么怎么求这两个函数得梯度呢，答案就是去使用反向传播算法。\n反向传播算法的核心就是去利用链式求导法则，对于两层或者更多层的神经网络来说，直接求得损失函数对于权重的梯度是一件不太好实现的事情，实际上ppt里面讲解的就是链式求导法则，为了更好的理解链式求导，这里以损失函数为交叉熵函数实现的多分类问题来进行记录。\n链式求导 上面构建了一个简单的二层网络，这个网络的工作流程是这样的\n计算得分\n与之前的线性网络一致，对于输入$X$来说，输出的得分就是 $$ scores = XW_1 + b_1 $$ 不同的是，为了拟合出更多的非线性边界，这里的得分还需要向第二层输出\n激活函数引入非线性\n假设我们的激活函数为$ReLu$函数，那么 $$ Z(x) = \\left{ \\begin{aligned} x , x \u0026gt;= 0\\ 0, else \\end{aligned} \\right. $$ 也就是隐藏层h1的输出就是$Z(scores)$\n经过隐藏层输输入后，我们可以把计算第二层的结果看作之前的线性分类器 即 $$ output = Z(scores)W_2 + b_2 $$ 得到这个output后，可以把结果转为softmax，也就是 $$ y_{pred} = argmax[softmax(output)] $$ 这样就可以使用交叉熵损失函数计算损失\n梯度求解 需要额外注意的是，W的梯度dW是在损失函数中学习到的，我们更新W的意义就是去最小化损失函数，最小化损失函数也就是意味着我们的预测越准确，模型所产生的误差越小。\n对于一个单层或者多层网络来说，其输入输出、求导方式都是很相似的，下面是一般求解步骤\n求得损失函数对输出的梯度dout\n在常见的一些损失函数如MSE均值、softmax交叉熵等，可以求得其关于输出的导数，即求得$\\frac{dL}{dout}$\n求得输出关于输入的梯度\n对于输出来说，一层网络的输出就是 $$ output = XW + b $$ 所以，对于，根据链式求导法则，我们就可以很容易的求出损失函数关于输入的梯度\n在使用激活函数后，即output其实并不是原始的输出，而是经过激活函数处理后的输出，这也就意味着中间又多了一层关于激活函数的导数，我们以ReLu激活函数为例\n一般的，如果不加激活函数，那么我们的求导过程可能是这样的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import torch # 假设我们已经知道损失函数关于输出的梯度 def backward(dout): \u0026#39;\u0026#39;\u0026#39; Inputs: - dout: Upstream derivative, of shape (N, M) - x: Input data, of shape (N, D) - w: Weights, of shape (D, M) - b: Biases, of shape (M,) \u0026#39;\u0026#39;\u0026#39; # 根据求导公式 dX = dout.mm(W.T) dW = x.T.mm(dout) db = dout.sum(dim = 0) return dX, dW, db 如果在输出层多加了激活函数，那么只需要再多计算一次乘积即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import torch def backward(dout): \u0026#39;\u0026#39;\u0026#39; Inputs: - dout: Upstream derivative, of shape (N, M) - x: Input data, of shape (N, D) - w: Weights, of shape (D, M) - b: Biases, of shape (M,) \u0026#39;\u0026#39;\u0026#39; # 计算dW的梯度 dW = x.T.mm(dout) # 注意，是由输出大于0的部分才有梯度，所以需要进行保留 dW[out \u0026lt; 0] = 0 更一般的，我们会直接对ReLu(x)做求导，从而当输入x发生变化时，我们的ReLu依旧会更加模块化\n作业 two_layer_net 讲解一下这个作业中较难的部分\n实现forward_pass 可以从函数的参数里面得到需要的参数， 例如W1, b1, W2, b2\n1 2 3 4 # Unpack variables from the params dictionary W1, b1 = params[\u0026#39;W1\u0026#39;], params[\u0026#39;b1\u0026#39;] W2, b2 = params[\u0026#39;W2\u0026#39;], params[\u0026#39;b2\u0026#39;] N, D = X.shape 需要额外注意的是这些参数的形状， 我们的训练数据X是NxD的，也就是说，这个训练集中有N个样本，每个样本都是简单的1xD向量，作业为了防止我们出错，还贴心的在注释里面给出了这些参数的形状\n1 2 3 4 5 6 7 8 \u0026#39;\u0026#39;\u0026#39; It should have following keys with shape W1: First layer weights; has shape (D, H) b1: First layer biases; has shape (H,) W2: Second layer weights; has shape (H, C) b2: Second layer biases; has shape (C,) - X: Input data of shape (N, D). Each X[i] is a training sample. \u0026#39;\u0026#39;\u0026#39; 根据这个注释，我们在做矩阵乘法的时候就特别方便\n1 2 3 4 # 第一层的输出 hidden = X.mm(W1) + b1 # 经过非线性激活函数 hidden[hidden \u0026lt; 0] = 0 此时，我们就得到了这个二层网络的隐藏层分数\n因此，计算输出的总分也是很简单\n1 2 # 未经softmax函数处理 scores = hidden.mm(W2) + b2 # raw_scores 到现在，我们就得到了网络的输出分数，现在让我们来梳理一下从图片到预测之间的流程\n3x32x32数据集\n我们把原始数据集展平为一个一维向量，把若干个这样的向量堆叠在一起，这样就得到了训练集X\n计算隐藏层输出\n与线性分类器计算分数一样，做乘法运算即可\n激活函数\n引入非线性，如ReLu, Sigmoid函数\n输出层\n得到隐藏层分数后计算输出层分数即可\nsoftmax得到概率\n我们把输出的scores经过softmax后得到近似概率分布，然后概率最高的就是我们网络将图片分类的结果\n交叉熵损失函数优化\n使用交叉熵函数优化，从而得到之前的W1, b1, W2, b2的梯度，并使用梯度下降法进行学习\n也就是说， 在forward_pass中，我们还剩最后两个步骤没有计算出来，下面我们将在nn_forward_backward中计算得出\nforward_backward 要想得到损失函数关于W1, b1, W2, b2的梯度， 我们得先求的损失函数，这里使用的是交叉熵损失函数，也就是说，我们需要求得softmax后的分数\nsoftmax过程\n这部分在A1中已经计算过，在这里在此计算一次。首先根据定义，其实就是每部分exp后除以总的exp和即可。我们的输出scores是一个NxC的矩阵，每一行(dim=1)的含义就是第i个样本(1\u0026lt;=i \u0026lt;=N)在10个类上的总分。例如，假如第i个样本在10个类中cat的分数最大，那么经过softmax后可以近似认为第i个样本是cat的概率最大\n1 2 3 4 5 6 7 8 9 10 11 12 # 从前向传播中得到分数,注意，这个分数其实是raw_scores scores, h1 = nn_forward_pass(params, X) # 得到分数后softmax化 # 得到每个类别的最大值 max_val, _ = torch.max(scores, dim=1) # 函数返回最大值和最大值的索引 # 除去最大值是防止exp值过大，同时不影响结果 scores_remove_max = scores - max_val.view(-1, 1) # 使用广播机制，不使用也可以 # scores_remove_max = scores - torch.max(scores, dim=1, keepdim=True).values # exp化 scores_exp = torch.exp(scores_remove_max) # 概率化 scores_prob = scores_exp / torch.sum(scores_exp, dim=1).view(-1, 1) # 不使用广播机制同上 链式法则\ndW2和db2\n在求得softmax化后的结果后，我们需要以损失函数的形式表达出来整个解，这里的损失函数是交叉熵损失函数，为了求得损失函数对W2的梯度，使用链式法则会更加简单清晰\n交叉熵损失 $$ Loss= -\\frac{1}{N}∑log(p_i)+reg⋅(∥W1∥^2+∥W2∥^2) $$ 这里的pi是预测值，也就是我们上面的softmax值，现在，我们可以把求解过程转换一下,即\n$$ \\frac{dL}{dW_2} = \\frac{dL}{dP} \\frac{dP}{dS} \\frac{dS}{dW_2} $$\n我们可以来挖掘一下Scores与W2的关系，显然有\n$$ Scores = h_1^T * W_2 + b_2 $$\n怎么求第一项的梯度呢？\n$ \\frac{dL}{dP} $的计算公式其实就是对数函数求导，而$\\frac{dP}{dS}$的结果就要从softmax公式出发\n$$ softmax(i) = \\frac{e^{scores_i}}{e^{scores}} $$\n这个时候就要分当前预测类的类别的情况了，因为对于$p_i$来说，每次都要计算两部分梯度，当计算类别正确时，也就是softmax公式的分子上是含有$e^y_i$，那么此时分子分母都是含有要求导部分；当求其它梯度时，分子上其实就是个常数，求导法则发生了变化。这里推荐一个视频,可能会帮助更好的理解。\n也就是说，对于这部分梯度来说，正确的类别结果-1(正确类别分子上还有求导到部分)，错误类别不需要-1，，而且对这部分求导是因为分母上有需要求导部分。\n而且，每个标签都是One-Hot格式，这样我们就可以求得$\\frac{dP}{dS}$\n所以求得$ \\frac{dL}{dS}$\n1 2 3 ds = scores_prob.clone() # NxC ds = ds[range(N), y] -= 1 ds /= N # 注意不要遗漏 $\\frac{dS}{dW}$ = h1(NxH)\n1 dW2 = h1.T.mm(ds) # HxC 同理也可以求得db2就是 ds\ndW1和db1\n这里同样使用的是链式法则\n$$ h1 = ReLu(XW_1+b_1) \\ Scores = h_1W_2 + b_2 $$\n所以要求 $$ \\frac{dL}{dW_1} = \\frac{dL}{dS} \\frac{dS}{dh1} \\frac{dh1}{dW_1} $$ 现在未知参数就是dh1,需要注意的是，因为是ReLu所以小于0的部分会置0\n1 2 dh1 = d_scores.mm(W2.T) dh1[h1 \u0026lt;= 0] = 0 # 小于等于0的不贡献梯度 这里不清晰的化还可以再加一部分即\n$$ \\frac{dh1}{dW_1} = X , h1 \u0026gt;= 0 $$\n现在，链式求导的部分我们就求解完了，也是这次作业最难的一部分。\n总结 多层感知机成功解决了线性分类不能完成的任务，但是多层感知机也有自身上的缺点，下节来看看大名鼎鼎鼎鼎大名的卷积神经网络！\n","date":"2024-11-23T16:48:55+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/","title":"神经网络——多层感知机"},{"content":"前言 继续来看看优化这部分\n梯度下降 优化部分主要讲解了与梯度下降以及梯度下降的各种优化版本\n虾几霸优化 对于评估一个W参数矩阵来说，需要计算出在这个W下的分类准确率即可。这里的”虾几把“的意思就是随机生成一个参数矩阵W，只要这个矩阵的准确率高于上一次计算的准确率，那么就把当前最优的W更新，然后一直模拟下去,一个可能的算法是这样的\n经过这种方法去求得的W在准确率大约在15%，不算太坏，但算不上好！\n梯度下降法 在一元函数中，导数可以理解为在这一点上的斜率，在多元函数中，我们使用梯度这个概念来进行导数的推广，实际上，梯度在每一维上的分量就是我们熟悉的导数\n沿着负梯度的方向就是目标函数下降最快的方向\n因此，对于损失函数来说，我们可以找到W的梯度矩阵dW，然后再对W进行优化,这种方法就是大名鼎鼎的梯度下降\n可以看到，这里我们就有了三个未决的超参数\n怎样初始化W 要迭代寻找多少次(num_steps) 学习率learning_rate 其中非常关键的一个参数就是learning_rate，因为最小化损失函数实际上就是去找到目标函数的极小值，在刚开始进行梯度下降时，初始位置在极小值的左边或者右边。下面用$ f(x) = sin(x) $来模拟一下整个过程\n当学习率很小时\n我们总能找到极值， 但是却要寻找很长时间，这是因为每一步都走的特别小，所以寻找要很长的时间，这里假设学习率是0.1，迭代100次\n当学习率很大时\n学习率很大，这就意味着每一步都走的很大，所以很容易错过最小值，从而造成振荡，下面是学习率为2的情形\n所以，这些参数的选取实际上是在训练神经网络的一些困难之处，而且我们的训练集通常很大，所以每次更换学习率后再训练的代价很大，来说一下这些优化方法！\n小批次计算 Mini Batch 在寻找学习率的时候，我们没必要在整个测试集上进行，而是去选择一批样本进行训练，其实这样做也可以减少内存的压力，一个可行的代码是\n1 2 3 4 5 6 7 import torch # 假设 X_train, y_train num_train = X_train.shape[0] # 得到样本总数 # batch size batch = 32 # 生成随机样本 idx = torch.randint(num_train, size=(batch, )) 这样，在每次训练的时候，我们就可以在小样本上进行迭代训练\n1 2 3 4 5 X_train_batch = X_train[idx] y_train_batch = y_train[idx] ############################ ... ############################ SGD+Momentum 在随机梯度中引入动量的概念，给我们的点增加一个“惯性”的特点\n可以看到， 我们的小球确实像物理中的小球那样，在不断的运动着！一个可能的代码是\n即先计算速度v，再根据速度v梯度下降\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 def f(x): return np.sin(x) def df(x): return np.cos(x) x0 = 1 # 初始化随机x v = x0 # 初始化 beta = 0.9 # 动量值 learning_rate = 0.1 # 学习率 for _ in range(50): # 迭代50次 v = beta * v + (1 - beta) * df(x0) x0 = x0 - learning_rate * v 这个动量的计算公式其实很有意思，它的前身或者本质就是指数加权平均。在使用随机梯度下降时，前面一时刻的梯度似乎不会对后面的梯度造成影响，这就导致随机梯度下降的过程是一个不断震荡的过程，而且很容易陷入局部最小值，而引入指数加权平均时，可以看到，每次梯度的更新都是取决于前面几次的平均值\n$$ v_{t+1} = \\beta * v_t + (1-\\beta)df(x) $$\n当$\\beta$取0.9时，也就是我们会取梯度的一个样本平均(假设样本为10)，这样就把之前计算过的梯度与现在联系在一起，从而避免震荡！\nNesterov Momentum 在ppt中的形式是这样的\nNesterov Momentum的改进思想在于，它在计算梯度之前，先对参数进行一个“预更新”，即朝动量方向提前迈出一步，这样梯度会变得更加准确。\nNesterov Momentum的更新公式为：\n预估下一步的位置：\n$$ \\tilde{\\theta} = \\theta_t + \\gamma v_t $$\n在预估位置上计算梯度：\n$$ v_{t+1}=γv_t−η∇f(θ~) $$\n更新参数：\n$$ θ_{t+1}=θ_t+v_{t+1} $$\n同样的，我们还可以使用这种方法去求sin(x)的极小值\n使用预估的x求梯度\n1 2 3 4 5 6 7 8 9 10 # 计算梯度下降路径 for _ in range(100): # 限定100步 # 预估位置 x_pred = x0 + beta * v # 在预估位置计算梯度 grad = df(x_pred) # 更新动量 v = beta * v - alpha * grad # 更新参数 x0 = x0 + v AdaGrad Adagrad 是一种自适应学习率的优化算法，它根据每个参数在训练过程中的历史梯度大小来调整学习率。对于稀疏特征或特征具有不同重要性的任务（如自然语言处理问题），Adagrad 具有较好的效果。\nAdagrad 的公式如下：\n更新梯度累积历史： $$ G_t=G_{t−1}+∇f(x_t)^2 $$\n这里 $G_t$是梯度平方的累计和（逐元素累加）。\n更新参数： $$ x_{t+1}=x_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\nabla f(x_t) $$\n$\\eta$ 是初始学习率。 $\\epsilon$ 是一个小值（如 $10^{-8}$），用于避免分母为零。 同样，我们来用sin(x)来模拟一下\n可以看到，在这种方法下，“小球”似乎没有它的“物理属性”！\nRMSProp RMSProp是AdaGrad引入指数衰减平均后的优化版本\n接着使用这种方法来求sin(x)的极小值\n有趣的一点是，与AdaGrad采取相同的学习率时，该方法产生了震荡，可能该方法在对学习率的初始值要求较高\nAdam Adma是RMSProp结合了Momentum的版本\n继续来寻找sin(x)的极小值点\n这是老师的经验，超参数的选择是个难点！\n总结 在了解这些优化技巧后，一个不错的建议是：优先使用Mini-batch和Adam优化。\n","date":"2024-11-15T20:20:39+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E4%BC%98%E5%8C%96%E4%B8%8E%E8%AE%AD%E7%BB%83/","title":"优化与训练"},{"content":"前言 好难好难\n线性分类器 线性模型 线性分类器在神经网络中相当于积木的低位\n你可以用很多层的线性分类器来实现一个神经网络，当然，为了提高模型拟合数据的能力，一般不会只去使用线性模型，而是会选择性的加入一些非线性模型\n从线性观点 让我们继续回到上几节课提到的CIFAR10数据集，这个数据集有10个不同的类别。而对于图像的表示，我们可以把图像(input)看作一个数字矩阵，我们想要实现的内容就是，对于一个数字矩阵，能否找到一个权重参数W,使得数据的结果发生一些变化，从而根据这个输出的结果来进行分类判断。\nWx + b是一个非常经典的线性模型\n例如，对于下面这个分类问题\n这里，我们假设输入的图像是一个简单的2x2的矩阵，也就是说，该图像仅仅只由4个特征点决定，那么，对于一个参数矩阵W来说，它的每一行可以看成是一个类别的权重，把这些元素对应相乘就可以得到该类别的\u0026quot;总分数\u0026quot;(例如，cat类在经过参数矩阵运算和bias之后的总分就是-96.8)。\n为了使表示结果更加的整洁易懂，我们可以把这个bias添加到参数矩阵W里面。\n从图像观点 这里的意思就是不把输入的数据拆分为一行，而是直接调整对应元素在图像中的数值\n给人在视觉上的观点就是给整个图像蒙上了一层模板，有着相同背景的图片更容易被划分到同一个类别中，也就意味着，每一类别好像是有了一张模板图片一样\n从几何上看 从几何上看，这些图片会被一个一个的超平面给划分切开，彼此之间没有交集\n线性模型不能解决的问题 线性模型显然不太适合取解决非线性模型。这里列出来一些线性分类器不能解决的问题。\n包括\n一三象限问题\n其实我觉得就是异或问题，对于这类问题，你无法找到一条直线来把两种颜色划分开来\n非线性问题\n对于这类数据一部分是呈现非线性的，除了非线性之外的数据是无法仅通过一条直线划分\n下面的图片很好的表明了这些例子。\n感知机不能学习异或问题！\n当然，如果一层感知机实现不了，那么就再来一层！天无绝人之路！\n损失函数 虽然线性模型很简单，但还是可以给我们许多启发。到目前为止，我们还没有给出一种可以更新权重W的一个方法，于是损失函数便登场了！\n损失函数可以理解为一个定量来分析真实值与我们的预测值之间的偏差的一个方式，按照这种方式，当我们的预测值越接近于真实值，那么我们可以认为，在这种条件下的W是loss友好的。\n另外说一点，在后续提到损失函数时，我们都更加倾向于这个损失函数是凸函数(Convex)，这样我们就可以通过导数解析的方式来求得损失函数最小时的权重W\nSVM损失函数 SVM的损失函数又叫做合页损失函数(hinge loss)，在上文中，我们提到可以使用一个线性分类器来对图像进行分类\n我们可以把一个这个结果S看成是线性变换后的结果，因此，对于每个图片，我们都可以通过这种方式来进行计算，从而得到它的一个分数\n其中，我们很有必要来展开阐述一下这个公式\n这个公式以得分输出的形式其实弱化了X W之间的关系，我们可以使用代码来进行描述\n假设这里有训练集X（X: A PyTorch tensor of shape (N, D) containing a minibatch of data.),并且给出了权重参数矩阵W（W: A PyTorch tensor of shape (D, C) containing weights.）\n也就是说，X的每张图片有D个特征，总共有N个样本；权重W有C个类别，每个类别有D个特征(按照列向量来说，每一个列对应一个图片)，这样，对于每一个样本X[i] (1xD)，我们都可以给这个图片计算出在不同类下面的分数\n1 2 3 4 5 6 7 8 import torch \u0026#39;\u0026#39;\u0026#39; X 是一个 NxD矩阵 W 是一个 DxC矩阵 \u0026#39;\u0026#39;\u0026#39; nums_train = X.shape[0] for i in range(nums_train): socres = W.t().mv(X[i]) # 得到这个图片在所有类上的分数 就像下面这个图片一样\n其中，假设X[0]是cat，那么我们就可以得到这张图片在10个类别上的对于分数;假设X[1]是car，那么我们同样可以得到car在10个类别上的分数，然后就可以得到所有的分数。\n注意一些技巧，我们想要统计的是在C个类上面的分数，所以输出的张量应该是Cx1或者1xC的;torch的mv函数很好的帮助我们将一个矩阵与一个向量相乘，在数学上的感受就是一个CxD的矩阵与一个Dx1的向量相乘，从而得到一个Cx1的输出分数\n再看SVM Loss 再看Loss函数，实际上做的就是一个衡量差值之间间隔的函数，方便起见，我们还是使用只有三个类和三个得分的输出\n怎么计算第一个cat的损失值呢？其实就是对于元素相加减，然后再与0作比较，所以cat的loss就是\n1 2 3 4 max(0, 5.1-3.2+1) + max(0, -1.7-3.2+1) Loss:2.9 同样我们也可以得到其它类的损失函数\n因此，这组数据的平均loss就是 Sum(loss) / x.shape[0]\n同样，我们还是可以使用代码来进行描述\n计算出所有类的分数\n这一步我们已经计算出\n找到对应正确的类，然后做加减法\n得到scores后，我们可以得到这个正确的类的分数。比如，第一张图片是cat，那么我们可以找到scores中是cat的分数是3.2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import torch \u0026#39;\u0026#39;\u0026#39; X 是一个 NxD矩阵 W 是一个 DxC矩阵 y: A PyTorch tensor of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 \u0026lt;= c \u0026lt; C. y[i] 就是X[i]的标签类 \u0026#39;\u0026#39;\u0026#39; num_train = X.shape[0] num_classes = W.shape[1] for i in range(num_train): socres = W.t().mv(X[i]) # 得到这个图片在所有类上的分数 correct_class_score = scores[y[i]] # 得到所有分数中, X[i]的分数 for j in range(num_classes): if j == y[i]: # 不与自已比较 continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin \u0026gt; 0: # 负分数不必相加 loss += margin 这样我们就得到这批样本的总的loss\n平均loss也可以求得\n1 loss /= num_train # 样本的总loss 除以 样本的总数量 矩阵形式 经过上面的铺垫，我们就可以为后面的矩阵求导做铺垫，现在让我们把这个hinge loss的公式展开\n因为我们不与自身作比较，所以，类的输出总分数就是 $$ W_j^{T} * X_i $$ 这个形式的意思就是$ W ^ T$的第j行实际上就是图像X[i]的参数，对应的，减去correct时的分数，而correct的表达可以是 $$ W_{y_i}^T * X_i $$ 然后累加和 $$ L_i = \\sum_{j \\neq y_i} \\max(0, w_j^T x_i - w_{y_i}^T x_i + \\Delta) $$ 我觉得这样写可以更加适合理解后面的梯度求导的形式！\n正则化 为了防止过拟合问题，我们可以给模型的参数W来加入一些惩罚项。\n首先我们来看看什么是过拟合。\n过拟合 以线性回归来举例，对于训练样本中的所有数据，如果我们的模型足够大、足够复杂，那么我们的模型就可以\u0026quot;记住\u0026quot;所有的点，于是，对于一个简单的样本来说，在训练后得到的模型大概是这样的：\n其中，f2是我们预期出现的模型性能的样子，正则化可以防止我们的模型拟合的过好，从而加强模型的预测能力。\nL1 L2正则化 正则化也有着不同的类别，常见的就是L1正则化和L2正则化\n其实正则化的目的就是去把W约束在一定的解的空间内，对于矩阵W来说，越简单的模型就意味着W值的某些取值取得越小，从而拟合出来得出现呈现出一些低阶多项式的形状，当我们把W的解约定在一定的取值内，我们假设这个取值是m，对于L1正则化的那个小尾巴 $ \\lambda R(W) $来说，其W的解 $$ 0 \u0026lt;= W_1 + W_2 + \u0026hellip;. + W_n \u0026lt;= m $$ 在二维空间内，我们可以得到这个解的区域是一个菱形区域(具体的数学证明设计凸优化的知识)\n同样的，对于L2正则化，我们同样要把参数W约束在一个范围内 $$ 0 \u0026lt;= W_1 ^ 2 + W_2 ^ 2 + \u0026hellip;.+W_n ^ 2 \u0026lt;= m $$\nL1 L2正则化在空间上的解释可以用下面这张图解释\nsoftmax与交叉熵损失函数 softmax函数常用于多分类问题，对于一组输出，比如说上面cat的输出，我们可以利用这个函数把各个输出的分数转换为概率来进行研究，其数学形式长这样\n分母是各个分数转化后的总和，分子是对于该类转化后的值\n交叉熵（Cross Entropy）是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。在信息论中，交叉熵是表示两个概率分布 $p$, $q$ 的差异，其中 $p$ 表示真实分布，$q$ 表示预测分布，那么 $H(p,q)$ 就称为交叉熵 $$ H(p,q)=\\sum_i p_i \\cdot \\ln {1 \\over q_i} = - \\sum_i p_i \\ln q_i \\tag{1} $$ 在这个问题中，对于第i类来说，其真实分布$p$的概率就是1，所以总的表达式又可以进行化简\n然后slices中有一个有趣的问题，当一个图片在一个有着C类的数据集上进行分类时，假设我们预测得到的这个图片是每某个类的概率差不多，那么交叉熵损失是多少？\n带入公式，实际上就是 $ -log \\frac{1}{C} $, 也就是 $ log C $\n对于这个数据集来说，C的数量是10\n总结 这次我们了解了很多损失函数和避免模型过拟合的方法，但是还没有了解怎么求得我们的最优的参数矩阵W，下次来了解一下求最优参数的方法！\n","date":"2024-11-13T08:49:49+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/","title":"线性分类器"},{"content":"前言 Pytorch实现KNN近邻算法的一些思路\n图像分类 图像分类是计算机视觉的核心任务，当给定我们的模型一张图片，我们的模型应该可以正确的给出图片上的物体的类别\n例如，图片上有一只cat,那么模型应该正确输出cat。\n图像分类所面临的挑战 semantic gap 语义差异 在人类看来，几乎不用思考就可以辨别出图像上的物体，但是机器却是无情的执行命令的机器，怎么把图像上所蕴含的信息传递给机器呢？于是便有了像素的表示，我们可以把一张图片细分为很多个小格子，显然，格子越多，这样图片就更加清晰，图片是以数字形式存储的，这种形式通常被称为数字图像。数字图像是由像素（picture elements）组成的矩阵，每个像素代表图像中的一个小点。所以，现在来看，这样图片就是一个数字矩阵\n图像旋转 虽然可以使用矩阵和数字的方法来表示一张图片，可是，按照这种方法，当把原始图片旋转之后，每个格子内的数字就会发生变化，对于人类来说，即便是把图片旋转后，也可以很简单的辨认出图片上的物体；而对机器来说，如果不加以处理，当模型接受到一个这样的图片后，很有可能会发生错误的预测。\n更多的挑战 不但要识别出图片中是什么，还要准确的指出它的类别。例如，照片中是一只猫，但是，是橘猫、布偶猫还是狸花猫呢 更难的，一些野生动物为了更好的适应所生存的环境，其颜色会和环境发生重叠，也就是所谓的保护色 这些都给我们带来了更多的挑战\n图像数据集 这里，老师给出了常见的数据集，并且也对比了其中的图片数量级\n其中，我只使用过MNIST数据集(手写体数字识别)，在本次作业中实现的KNN近邻算法使用的是CIFAR10，与CIFAR100主要的区别就是总共只有10个类别，每个类别里面有很多张图片。选择这个数据库的原因是，MNIST中的数据太少，而ImageNet和Places365数据太多，折中选择了这个数据集。\nKNN近邻算法 对于这类算法，一般有两个通用的API\n训练\n1 2 3 def train(images, labels): # To do return modle 预测\n1 2 3 def predict(modle, test_images): # To do return test_labels 这个算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数都属于某一个类别，则该样本也属于这个类别。意思就是，对于一个预测的样本，如果离这个样本最近的数据都是属于A类别，那么这个要预测的样本很有可能就是A类别，毕竟它们很相似！\nL1距离 这里的距离指的就是曼哈顿距离,计算方法就是对应坐标作差后取绝对值。\nL2距离 L2距离指的是欧式距离，也就是在空间中计算两个点之间对应坐标距离的方法\n代码实现 现在来实现一下上文中提到的两个API，简单起见，这里使用numpy\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import numpy as np class KNN: def __init__(): pass def train(self, X, y): \u0026#39;\u0026#39;\u0026#39; X指的是输入的训练数据 y指的是训练数据对应的类别 \u0026#39;\u0026#39;\u0026#39; self.X = X self.y = y def predict(self, X): # X是输入的，需要预测其类别的test数据 num_test = X.shape[0] # 样本类别数 Ypred = np.aeros(num_test, dtype=self.y.dtype) # 遍历所有test数据，给test数据中的每个数据找到其距离最近的那个图像 for i in range(num_test): # 计算L1距离 dis = np.sum(np.abs(X[i, :] - self.X), axis = 1) # 找到其中距离最近的那个值对应的index，进而获得它的类别 min_idx = np.argmin(dis) # 对应的标签就是self.y的标签 Ypred[i] = self.y[min_idx] return Ypred 这里的predict使用的是显示loop,这种情况会特别耗时！\nk的取值 上面的代码没有显示的指定k的取值范围，而是直接使用k=1这个取值，首先，这样做很简单，因为只需要查看离测试样本距离最近的那个类是什么类型即可。但是，这种操作会使得算法会对异常值特别敏感，同时，不同类别之间的边界也是突出状而不是趋于平滑\n因此，我们可以提高k的取值，提高k值也减少了异常值对test数据的影响，因为test数据这次有k个不同的参考意见，而不是只去参考一个值。\n使用Pytorch来实现KNN算法 首先是计算两个向量之间的距离\n双重循环 This implementation uses a naive set of nested loops over the training and test data. The input data may have any number of dimensions \u0026ndash; for example this function should be able to compute nearest neighbor between vectors, in which case the inputs will have shape (num_{train, test}, D); it should also be able to compute nearest neighbors between images, where the inputs will have shape (num_{train, test}, C, H, W). More generally, the inputs will have shape (num_{train, test}, D1, D2, \u0026hellip;, Dn); you should flatten each element of shape (D1, D2, \u0026hellip;, Dn) into a vector of shape (D1 * D2 * \u0026hellip; * Dn) before computing distances.\n这里是老师给的一些代码的预处理的关键提示\nMore generally, the inputs will have shape (num_{train, test}, D1, D2, \u0026hellip;, Dn); you should flatten each element of shape (D1, D2, \u0026hellip;, Dn) into a vector of shape (D1 * D2 * \u0026hellip; * Dn) before computing distances.\n对于所有的输入向量，不管是什么维度的样本，我们都可以转换为一个二维张量，这样做可以简化一些计算，同时使得结果更加清晰。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import torch def compute_distances_two_loops(x_train: torch.Tensor, x_test: torch.Tensor): \u0026#34;\u0026#34;\u0026#34; Args: x_train: Tensor of shape (num_train, D1, D2, ...) x_test: Tensor of shape (num_test, D1, D2, ...) Returns: dists: Tensor of shape (num_train, num_test) where dists[i, j] is the squared Euclidean distance between the i-th training point and the j-th test point. It should have the same dtype as x_train. \u0026#34;\u0026#34;\u0026#34; num_train = x_train.shape[0] # 得到行数 num_test = x_test.shape[0] dists = x_train.new_zeros(num_train, num_test) # dists[i, j]是第i个x_train与x_test的距离 x_train_flat = x_train.view(num_train, -1) x_test_flat = x_test.view(num_test, -1) for i in range(num_train): for j in range(num_test): diff = x_train_flat[i] - x_test_flat[j] dists[i, j] = torch.sum(diff ** 2) return dists 这样做十分清晰，而且不开根是因为我们不需要得到确切的欧氏距离，只是单纯的比较大小，所以直接返回距离的平方即可。\n但是，这样并没有利用pytorch,会导致计算速度减慢，看看怎么优化！\n一重循环 这里使用的其实是一个高级特征，通过下标索引来访问元素(熟悉numpy的肯定不陌生)\n1 2 3 4 5 6 7 8 9 10 11 12 13 def compute_distances_one_loop(x_train: torch.Tensor, x_test: torch.Tensor): num_train = x_train.shape[0] num_test = x_test.shape[0] dists = x_train.new_zeros(num_train, num_test) x_train_flat = x_train.view(num_train, -1) x_test_flat = x_test.view(num_test, -1) for i in range(num_train): diff = x_train_flat[i] - x_test_flat # 计算每个x_train与x_test dists[i, :] = torch.sum(diff ** 2, dim=1) # 按照行进行求和 return dists 其中，diff = x_train_flat[i] - x_test_flat 这行代码可以自动帮我们计算第i个x_train与所有的x_test的差值，然后按照行的顺序进行求和(dim=1，numpy的是axis = 1)。\nNo loop 不使用循环 可以说不使用循环才是KNN里面一个十分精彩的部分，这里用到了高级机制BoardCast广播机制，下面我们来看一看这个部分的数学表达形式。\n图片来自bilibili视频.\n这里还需另外提醒的是矩阵的加减法，对于两个维数相同的矩阵$A 和B$，经过运算后得到$C$,其中，$$ C_{ij} = A_{ij} + B_{ij} $$\n$$ C_{ij} = A_{ij} - B_{ij} $$\n即对应元素相加减的操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 def compute_distances_no_loops(x_train: torch.Tensor, x_test: torch.Tensor): num_train = x_train.shape[0] num_test = x_test.shape[0] dists = x_train.new_zeros(num_train, num_test) x_train_flat = x_train.view(num_train, -1) x_test_flat = x_test.view(num_test, -1) x_train_squre = torch.sum(x_train_flat ** 2, dim = 1) x_test_squre = torch.sum(x_test_flat ** 2, dim = 1) # 计算点积 temp = x_train_flat @ x_test_flat.t() dists = x_train_squre.view(-1, 1) + x_test_squre.view(1, -1) - 2 * temp return dists 根据上面的计算结果，x_train是一列的张量，x_test是一行的张量，从而两者进行广播后运算，值得注意的是，两者的内积可以转换为矩阵相乘的形式。\n预测predict 在计算出每个测试样本与(x_test)每个训练样本(x_train)的距离之后，对于每个测试样本，我们就可以找到其前k个最近值，然后确定其类别后返回。\n一个可能的函数看起来可能是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def predict_labels(dists: torch.Tensor, y_train: torch.Tensor, k: int = 1): num_train, num_test = dists.shape y_pred = torch.zeros(num_test, dtype=torch.int64) for j in range(num_test): # 遍历x_test数据 # 找到每个测试样本最近的k个训练样本的距离和索引 dists_k, indices = torch.topk(dists[:, j], k, largest=False) # largest=False 是升序 # 获取这些最近的k个训练样本的标签 nearest_labels = y_train[indices] # 计算每个标签的出现次数并选择出现次数最多的标签 labels, counts = torch.unique(nearest_labels, return_counts=True) # 记录最大出现次数 max_count = torch.max(counts) # 找到出现次数是最大出现次数的那个标签 most_common_labels = labels[counts == max_count] # 在计数最多的标签中选择数值最小的那个标签 y_pred[j] = torch.min(most_common_labels) return y_pred 这个代码的思路就是，寻找距离test数据的最近的k个不同类别，返回其出现次数最多的那个类别，如果有两个类别出现次数相同，那么就返回距离最近的那个。\n交叉验证 k折交叉验证（英语：k-fold cross-validation），将训练集分割成k个子样本，一个单独的子样本被保留作为验证模型的数据，其他k − 1个样本用来训练。交叉验证重复k次，每个子样本验证一次，平均k次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10次交叉验证是最常用的。\n对于原始数据 (raw 数据)，如果全部用于训练，则无法评估模型在未见过的数据上的表现，从而无法验证模型的有效性和准确性。因此，通常会将数据划分为两部分，一部分用于训练 (train)，另一部分用于测试 (test)，从而在测试集上评估模型的表现。\n在实际应用中，为了更好地选择超参数，我们会引入一个额外的数据集，称为验证集 (validation)。这样，数据集可以划分为三部分：训练集 (train)、验证集 (validation) 和测试集 (test)。\n具体流程如下：\n训练集：用于训练模型，使模型能够学习数据的特征和模式。 验证集：用于选择超参数。我们在验证集上测试不同的超参数组合，并选择在验证集上表现最好的参数设置。 测试集：在完成超参数选择后，我们在测试集上评估最终模型的性能。测试集完全不参与训练和参数选择，因此可以真实反映模型在新数据上的表现。 这种三分法的优势在于，验证集用于超参数选择，而测试集则用来评估模型在未见过的数据上的泛化能力，从而避免在超参数选择过程中过拟合测试集的风险。\n有关交叉验证的部分解释来自ChatGPT\n交叉验证 (Cross-Validation) 是一种用于更稳健地评估模型性能和选择超参数的方法。它通过多次数据划分和训练测试来减少模型对数据划分的偶然影响。在交叉验证中，我们通常将数据划分为多个等大小的部分（称为“折”或“folds”），并在每次训练时使用不同的折组合来训练和测试模型。\n交叉验证的数据划分步骤 以常用的 K 折交叉验证 (K-Fold Cross-Validation) 为例，具体步骤如下：\n将数据分成 K 个等大小的折：将数据集均匀分成 K 个折，记为 fold_1, fold_2, ..., fold_K。通常，K 的值是 5 或 10。\n多次训练和验证：对于每次迭代（共 K 次），使用 K-1 个折作为训练集，剩下的一个折作为验证集。具体来说：\n第一次迭代：使用 fold_2 到 fold_K 作为训练集，fold_1 作为验证集。 第二次迭代：使用 fold_1 和 fold_3 到 fold_K 作为训练集，fold_2 作为验证集。 以此类推，直到每个折都被用作一次验证集。 计算平均性能：在每次迭代中记录模型在验证集上的性能（例如准确率、损失等），然后将 K 次的验证结果平均，作为该模型在该超参数下的总体验证性能。\n选择最佳参数：对于每个超参数组合，都进行上述 K 次交叉验证，并根据平均性能选择表现最好的参数组合。\n最终测试：完成超参数选择后，可以在独立的测试集上评估模型的最终性能。\n交叉验证的优势 交叉验证避免了简单的训练/验证分割可能带来的偶然性，使模型能更稳健地评估数据上的表现。此外，交叉验证可以最大化地利用数据，因为每个数据点都能在验证集中出现一次，同时也在训练集中使用 K-1 次。这种方法尤其适合数据量较小的场景。\n总结 为了避免数据划分的偶然，我们保持三部分总体不变，对于train validation部分做出变化。\n我们把上面train数据分为nums个，每一块叫做一个fold, 假设分为5个fold，对于我们的待选参数集K来说，对于第i个参数K[i]，每次都选择1个fold作为验证集(validation)，剩下的4个作为训练集，然后再计算其准确率，对于K[i]来说，我们就得到了5个不同的准确率，然后可以取平均(mean)，作为选择K[i]为参数是的准确率，最后通过准确率就可以选出最优的K。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def knn_cross_validate( x_train: torch.Tensor, y_train: torch.Tensor, num_folds: int = 5, k_choices: List[int] = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100], # 待选K ): x_train_folds = list(torch.chunk(x_train, num_folds)) # 把数据拆分为 num_folds块 y_train_folds = list(torch.chunk(y_train, num_folds)) k_to_accuracies = {k: [] for k in k_choices} # 使用键值对进行存储 for k in k_choices: for j in range(num_folds): x_val = x_train_folds[j] # 获取第j个验证集 y_val = y_train_folds[j] x_train_fold = torch.cat([x_train_folds[i] for i in range(num_folds) if i != j], dim=0) # 剩下的num_folds作为训练集 y_train_fold = torch.cat([y_train_folds[i] for i in range(num_folds) if i != j], dim=0) classifier = KnnClassifier(x_train_fold, y_train_fold) acc = classifier.check_accuracy(x_val, y_val, k) # 计算准确率 k_to_accuracies[k].append(acc) return k_to_accuracies 总结 KNN近邻算法还是非常适合初学者入门的，其中主要难点或者说比较新鲜的点就是广播机制BoardCast以及交叉验证的代码实现！\n","date":"2024-11-08T17:54:16+08:00","permalink":"https://XiaoPeng0x3.github.io/p/image-classifier%E7%AC%94%E8%AE%B0/","title":"Image Classifier笔记"},{"content":"数据泛化 一些常见的统计方法 mean：均值，对于一组数据来说，计算其均值可以直接使用np.mean来进行计算，对于多维数据，numpy引入了轴axis的概念，其中，轴的起点从0开始一直到n，例如，在二维数据中，其中每一行代表一个样本，每一列代表一个特征(类似于csv文件)\n​\t长,宽,高\nx1\t1,2,3\nx2\t1,4,5\nx3\t1,6,7\n对于这样一组数据，用列表来表示就是\n1 2 3 4 data = [x1, x2, x3] data = [[1,2,3], [1,4,5], [1,6,7]] 其中，按照axis=0的方式来计算均值，这里计算的就是长、宽、高 每个特征的均长、均宽、均高，按照axis = 1来进行计算，也就是计算每一行的均值，也就是每一个样本的均值(看起来没有什么意义)\n1 2 mean1 = np.mean(data, axis=0) # 按照列进行计算 mean2 = np.mean(data, axis=1) # 按照行进行计算 下面所有的方法var(方差)，std(标准差)等均可以按照不同的轴进行计算\nvar:variance，方差，不在叙述计算公式，可以直接使用np.var()\nstd：Standard deviation,可以根据方差得到,可以直接使用`np.std()\nnp.round:保留小数操作，例如，要对data保留三位小数，可以表示为\n1 ans = np.round(data, 3) min-max均值规化 公式为\n$$ x\u0026rsquo; = \\frac{x-min}{max-min}$$\n对于一组数据data,可以这样计算\n1 2 3 4 5 def MinMax(data:np.ndarray) -\u0026gt; np.ndarray: data_max = np.max(data, axis=0) data_min = np.min(data, axis=0) ans = (data - data_min) / (data_max - data_min) return ans 标准化 标准化可以把各个特征标准化为标准差为1，均值为0的正态分布\n公式为\n$$ x = \\frac{x-\\mu}{\\sigma} $$\n其中， $\\mu$是均值，$\\sigma$是标准差\n1 2 3 4 5 def Standardization(data: np.ndarray) -\u0026gt; np.ndarray: data_mean = np.mean(data, axis=0) data_std = np.std(data, axis=0) ans = (data - data_mean) / data_std return ans 总结 是否必须使用标准化方法？\n算法需求： 某些算法（如距离-based的算法, K-means, K邻近）对特征尺度非常敏感，标准化几乎是必需的。 某些算法（如决策树、随机森林等）对特征尺度不敏感，标准化不是必需的。 数据特性： 如果特征的数值范围已经很接近，标准化的效果可能不明显。 如果特征的数值范围差异很大，标准化可以显著提升模型性能。 模型性能： 通过实验比较标准化前后的模型性能，可以决定是否需要标准化。 ","date":"2024-11-04T10:43:36+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E6%95%B0%E6%8D%AE%E6%B3%9B%E5%8C%96/","title":"深度学习基础系列：数据泛化"},{"content":"reshape reshape可以改变矩阵的维度，例如，有一个一维矩阵\n1 2 3 4 import numpy as np a = np.arange(20) # 转变为四行五列 ans = np.reshape(a, (4,5)) # 传入一个元组 转化前后数据量是一致的，20个元素不可以转换为3行4列\n","date":"2024-11-03T23:19:33+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E7%9F%A9%E9%98%B5%E5%8F%98%E5%9E%8B/","title":"深度学习基础系列：矩阵变型"},{"content":"矩阵的转置 矩阵的转置可以说是一个很常见的矩阵操作了，对于简单的矩阵(二维及以下)的矩阵来说，只需要调用numpy的T属性即可，例如\n1 2 3 4 5 6 7 import numpy as np a = [[1,2,3], [3,4,5], [5,6,7]] a_nparray = np.array(a) # 转换为ndarray a_T = a_nparray.T # 是一个属性 或者直接使用transpose\n1 2 3 4 5 6 import numpy as np a = [[1,2,3], [3,4,5], [5,6,7]] a_nparray = np.transpose(a) ","date":"2024-11-03T22:56:32+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE/","title":"深度学习基础系列：矩阵转置"},{"content":"Softmax函数 softmax函数常用于多分类问题，我们希望模型的输出可以作为预测的概率，即输出值越大的那个参数在预测的时候很有可能就是正确答案。\n但是回想一下概率的计算公式(扔骰子)，对于总的概率空间样本来说，其概率的总和一定是1，而我们的预测输出基本上总和不可能是1，这里softmax函数的作用就是压缩这些输出值，从而使用概率的方式进行表示\nsoftmax函数长这样\n给定一个K维向量$ z=[z_1,z_2,\u0026hellip;,z_K]$，Softmax函数的定义为：\n这里，$\\mathbf{z}$ 是一个K维向量，$z_j$ 是向量中的第 $j$ 个元素，$ 1 \\leq j \\leq K$。\n$$ \\sigma(\\mathbf{z})j = \\frac{e^{z_j}}{\\sum{k=1}^{K} e^{z_k}} $$\n计算过程 对于给定的一个list输入，先计算得到softmax函数的分母值\n1 2 3 4 5 6 7 8 9 10 11 12 13 import math input = [1, 2, 3] # 分母是math.exp形式 ans = list() sumVal = 0.0 for val in scores: sumVal += math.exp(val) # 分母 for val in scores: ans.append(math.exp(val) / sumVal) print(ans) 我们也可以使用numpy进行计算\n1 2 3 4 5 6 7 8 import numpy as np def softmax(scores: list[float]) -\u0026gt; list[float]: temp = np.array(scores) # 转换为ndarray exp_temp = np.exp(temp) # 计算所有值的exp值 exp_sum = np.sum(exp_temp) # 和为分母 # 计算分子 exp_temp ans = np.round(exp_temp / exp_sum, 4) # 每个exp值除以分母，并保留4位小数 return ans numpy的方便之处在于不用编写循环和计算快！\n","date":"2024-11-02T10:46:57+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97softmax/","title":"深度学习基础系列：softmax"},{"content":"上次我们了解了怎么用Go语言来创建和连接一个socket，这里来看一看怎么封装用户行为以及怎么实现用户广播上线功能\nServer的封装 server 这是在上一节中提到的server结构\n1 2 3 4 type Server struct { Ip string Port int } 可以看到，我们只有两个简单的成员属性，为了实现用户上线后全部广播的操作，我们需要在server中记录下来每次连接到server的client，这里可以使用map来进行记录，同时，为了实现全局广播的效果，我们可以在server中使用一个chan来进行管理。\n为什么要实现server要实现一个chan通道呢，当有用户上线建立连接后，我们就可以把上线的这个消息发送给chan来进行管理，然后遍历map就可以实现广播的操作。\nserver的实现 需要在原来的基础上多增加一些属性\n1 2 3 4 5 6 7 8 9 10 type Server struct { Ip string Port int // 创建用户表 OnlineMap map[string]*User // 同步的锁 mapLock sync.RWMutex // 负责全局广播的chan Message chan string } 在创建好一个server后，与上一篇文章一样，使用协程去处理连接之后的状态\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 func (this *Server) Start() { // 创建好一个监听对象 // 这个函数会有两个返回值 // 一个是创建的 listen对象， 一个是是否创建成功 listener, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, this.Ip, this.Port)) // 创建失败的话， err就会有一个失败code // err != nil 就是说明创建失败 if err != nil { fmt.Println(\u0026#34;创建监听对象失败！, err\u0026#34;, err.Error()) return } // 启动之后记得关闭，避免浪费资源 defer listener.Close() // 然后就是使用accept方法 // 在一个循环里面不停的接受数据 // 监听 // 全局管道 go this.ListenMessage() for { // 这里的 meaage 是net.Coon类型 conn, err := listener.Accept() // 说明接收到了数据 if err != nil { fmt.Println(\u0026#34;监听失败！\u0026#34;) continue } // 打开一个协程去处理 go this.Handle(conn) // 下面的代码不会阻塞 } } 这里的Handle方法可以去处理连接请求，有哪些请求呢？\n当一个用户上线后，应该把这个用户添加到Online表中 广播这个用户上线的消息 看到这里，起始我们缺少封装的user类，我们可以再封装一个user类\nUser的封装 user类的实现 在user里面，基本的属性有Name, Address这些操作，为了更加方便User把消息转发给client(转发操作指的是conn.Write操作)，在消息接收的上我们可以初始化一个chan来进行连接转发\n1 2 3 4 5 6 type User struct { Name string Addr string C chan string conn net.Conn } C是为了接受来自server的消息，conn是为了把消息转发给client，那么在初始化的时候，就得去监听，看是否有消息写回来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func NewUser(conn net.Conn) *User { userAddr := conn.RemoteAddr().String() // 可以得到客户端的地址 user := \u0026amp;User{ Name: userAddr, Addr: userAddr, C: make(chan string), conn: conn, } go user.ListenMessage() return user } // ListenMessage 监听User的chan func (this *User) ListenMessage() { for { mes := \u0026lt;-this.C this.conn.Write([]byte(mes + \u0026#34;\\n\u0026#34;)) } } 这样，在实现连接之后，我们就可以添加用户到在线表里面去\n1 2 3 4 5 6 7 8 9 10 11 12 func (this *Server) Handle(conn net.Conn) { // fmt.Println(\u0026#34;连接成功！\u0026#34;) // 执行到这里，说明已经有一个用户上线 newUser := NewUser(conn) this.mapLock.Lock() this.OnlineMap[newUser.Name] = newUser this.mapLock.Unlock() // 广播该用户已上线 this.Boardcast(newUser, \u0026#34;I am in!\u0026#34;) } user用户上线的广播 怎么实现Boardcast方法呢？可以直接利用server里面的chan来实现\n1 2 3 4 5 func (this *Server) Boardcast(u User, mes string) { // 把上线的消息发送给message chan sendMes := \u0026#34;[\u0026#34; + user.Name + user.Addr + mes + \u0026#34;]\u0026#34; this.Message \u0026lt;- sendMes // 发送给管道 } 在发送给管道后，server中的管道就就得到了数据，因此，就可以直接通过server中的chan进行消息的传输，遍历Onlinemap即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 func (this *Server) ShareMessage() { // 只要message有消息 // 那么就发送给在线的所有用户 for { mes := \u0026lt;-this.Message for _, user := range this.OnlineMap { this.mapLock.Lock() user.C \u0026lt;- mes this.mapLock.Unlock() } } } 最后在服务启动的时候去监听转发信息功能即可\n总结 整个流程看起来是这样的\n创建tcp套接字并开启连接 连接后会创建User对象 User对象会向Server的message发送信息 server的message接收到信息之后会遍历整个Online表，把User上线的消息发送给在Online表中的每一个User 其中，消息的转发依赖于conn.Write，User上线后把上线消息写入Serevr的chan，Server再把该User上线的消息通过Online表写入User的chan。\n","date":"2024-11-02T09:09:40+08:00","permalink":"https://XiaoPeng0x3.github.io/p/tcp%E8%81%8A%E5%A4%A9%E5%AE%A4%E4%BA%8C%E7%94%A8%E6%88%B7%E4%B8%8A%E7%BA%BF%E5%92%8C%E5%B9%BF%E6%92%AD/","title":"TCP聊天室(二)：用户上线和广播"},{"content":"前言 在学习完Go语言之后，总是感觉没有合适的上手项目进行练习，最近正好看到一个TCP网络聊天室的小项目，这个项目只使用基础的包而不使用任何框架，非常适合练手。\n需要的工具有\nGo开发环境 nc工具，方便模拟client进行测试 建立连接 在Go中，我们可以使用net包来进行基本的server的socket的创建，也就是net.Listen方法\n1 net.Listen() 下面是这个函数的原型\n1 2 3 4 5 // The network must be \u0026#34;tcp\u0026#34;, \u0026#34;tcp4\u0026#34;, \u0026#34;tcp6\u0026#34;, \u0026#34;unix\u0026#34; or \u0026#34;unixpacket\u0026#34;. func Listen(network, address string) (Listener, error) { var lc ListenConfig return lc.Listen(context.Background(), network, address) } 可以看到，函数的两个参数都是string类型的，第一个参数指定的是通信的网络(可以直接指定tcp), 第二个是server的地址。返回值就是监听对象和err\n例如，我们想要启动一个监听,就可以这样写\n1 2 3 4 listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;) if err != nil { // To do } 就创建好了一个scoket\n在得到listener后，要开启接受功能，可以调用\n1 listener.Accept() 同样，这个函数有两个返回值，正常使用是这样的\n1 2 3 4 conn, err := listener.Accept() if err != nil { // To do } 其中，返回的是一个net.Conn类型的参数，可以通过conn在socket之间传递数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type Conn interface { // Read reads data from the connection. // Read can be made to time out and return an error after a fixed // time limit; see SetDeadline and SetReadDeadline. Read(b []byte) (n int, err error) // Write writes data to the connection. // Write can be made to time out and return an error after a fixed // time limit; see SetDeadline and SetWriteDeadline. Write(b []byte) (n int, err error) // Close closes the connection. // Any blocked Read or Write operations will be unblocked and return errors. Close() error // LocalAddr returns the local network address, if known. LocalAddr() Addr // RemoteAddr returns the remote network address, if known. RemoteAddr() Addr // ........ // ........ } conn.Read可以从连接中读取数据(server可以read来自client的数据)， 同时conn.Write可以从连接中发送数据(server向client发送数据)\n这里就实现了通信的基石，即发送和接受数据，其整个过程就是\n创建socket：net.Listen,返回一个net.Listener对象 开始接收请求：listener.Accept,返回一个net.Conn对象 使用net.Conn实现接收数据和发送数据 simple demo 这里创建一个简单的demo程序，在server接收到来自client的数据后，把接受到的数据全部转换为大写后发送给client\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { ip := \u0026#34;127.0.0.1\u0026#34; port := 8080 //CreateServer(ip, port) listener, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, ip, port)) defer listener.Close() if err != nil { fmt.Println(\u0026#34;Eror!\u0026#34;, err) return } buf := make([]byte, 1024) conn, err := listener.Accept() defer conn.Close() for { if err != nil { fmt.Println(\u0026#34;connect fail\u0026#34;, err) return } // 读取数据 conn.Read(buf) // 写回数据 conn.Write(bytes.ToUpper(buf)) } } 然后使用nc工具\n1 nc 127.0.0.1 8080 当我们发送hello的时候，server正确的返回了HELLO\n思考：当有多个client的时候怎么办？\n协程处理 只有一个用户创建连接的时候可以正常返回，但此时有多个用户创建了连接请求，由于我们只accept了一次连接请求，所以当多个用户尝试连接的时候，第二个及之后的那些用户无法与服务器建立连接。\n解决办法\n每次在循环的过程中不断的进行监听，而不是只监听一次。 原始代码是\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // ..... conn, err := listener.Accept() // 把这里添加到循环中 defer conn.Close() for { if err != nil { fmt.Println(\u0026#34;connect fail\u0026#34;, err) return } // 读取数据 conn.Read(buf) // 写回数据 conn.Write(bytes.ToUpper(buf)) } } 添加到循环后就可以不断的建立连接\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // ...... for { conn, err := listener.Accept() if err != nil { fmt.Println(\u0026#34;connect fail\u0026#34;, err) return } // 读取数据 conn.Read(buf) // 写回数据 conn.Write(bytes.ToUpper(buf)) } } 然后再新建client的时候就可以处理多用户连接。\n这样写有什么问题？\n可以发现，当在一个client发送第二组数据后，server什么都没有返回，这是因为在循环执行到\n1 conn.Write(bytes.ToUpper(buf)) server一直在期待新的链接，而不是去处理之前的client的数据\n使用go协程\n在每次conn成功后，为了保持后续的链接，可以把后续的read和write封装为go协程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func Handler(conn net.Conn) { defer conn.Close() buf := make([]byte, 1024) for { cnt, _ := conn.Read(buf) conn.Write(bytes.ToUpper(buf[:cnt])) } } func main() { ip := \u0026#34;127.0.0.1\u0026#34; port := 8080 //CreateServer(ip, port) listener, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, ip, port)) defer listener.Close() if err != nil { fmt.Println(\u0026#34;Eror!\u0026#34;, err) return } //defer conn.Close() for { conn, err := listener.Accept() if err != nil { fmt.Println(\u0026#34;connect fail\u0026#34;, err) return } go Handler(conn) } } 也就是说在主函数内，只负责去监听是否有用户链接，而链接后的读写就去创建一个新的协程，在这个协程内根据这个链接不断的去实现client-server之间的读写。\n总结 net.Listen：创建tcp socket, 返回listener对象 listener.Accept：监听客户端的连接, 返回net.Conn连接对象 net.Conn：实现read和write，读取和发送数据 go：开启一个协程 ","date":"2024-11-01T17:43:28+08:00","permalink":"https://XiaoPeng0x3.github.io/p/tcp%E8%81%8A%E5%A4%A9%E5%AE%A4%E4%B8%80tcp%E9%80%9A%E8%AE%AF/","title":"TCP聊天室(一)：tcp通讯"},{"content":"协方差矩阵 协方差(covariance)可以用来观测变量之间是否存在线性相关性。然而，协方差本身有一些局限性，因此在实际应用中，我们通常还会使用相关系数来进一步评估变量之间的相关性。\n协方差的局限性 尺度依赖性：\n协方差的值受变量尺度的影响。如果一个变量的值范围很大，而另一个变量的值范围很小，即使它们之间有很强的线性关系，协方差的绝对值也可能很大或很小，这使得直接比较不同变量之间的协方差变得困难。 单位依赖性：\n协方差的单位是两个变量单位的乘积。例如，如果一个变量的单位是米，另一个变量的单位是秒，那么协方差的单位将是米·秒。这使得协方差的解释更加复杂。 相关系数 为了克服协方差的这些局限性，我们通常使用 皮尔逊相关系数（Pearson correlation coefficient），它是一个标准化的协方差，范围在 -1 到 1 之间。\n皮尔逊相关系数的定义 皮尔逊相关系数 ( r ) 定义为： $$ r_{XY} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y} $$\n其中：\n$\\sigma_X $ 是 X 的标准差。 $\\sigma_Y$ 是 Y 的标准差。 解释 ( r = 1 )：完全正相关，即两个变量完全同向变化。 ( r = -1 )：完全负相关，即两个变量完全反向变化。 ( r = 0 )：没有线性相关性。 ( |r| ) 接近 1：表示强相关性。 ( |r| ) 接近 0：表示弱相关性或没有相关性。 Python 示例 可以使用 numpy 或 pandas 库来计算皮尔逊相关系数。\n使用 numpy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import numpy as np # 示例数据 data = np.array([ [1, 4], # 观测值1 [2, 5], # 观测值2 [3, 6] # 观测值3 ]) # 计算协方差矩阵 cov_matrix = np.cov(data, rowvar=False) print(\u0026#34;协方差矩阵:\\n\u0026#34;, cov_matrix) # 计算相关系数矩阵 corr_matrix = np.corrcoef(data, rowvar=False) # correlation coefficient print(\u0026#34;相关系数矩阵:\\n\u0026#34;, corr_matrix) 这里的np.cov()和np.corrcoef()，如果不指定第二个参数，那么第二个参数默认rowvar = True，意思就是这组数据是按照横向放置的，意思就是每一行是一个属性\n而在有时候需要从文件里面读取一些属性，例如\n1 2 3 X\tY\tZ x1\ty1\tz1 x2\ty2\tz2 那么这个时候，就可以把默认值设置为False,代表每一列是一个属性\n使用 pandas 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import pandas as pd # 示例数据 data = pd.DataFrame({ \u0026#39;X\u0026#39;: [1, 2, 3], \u0026#39;Y\u0026#39;: [4, 5, 6] }) # 计算协方差矩阵 cov_matrix = data.cov() print(\u0026#34;协方差矩阵:\\n\u0026#34;, cov_matrix) # 计算相关系数矩阵 corr_matrix = data.corr() print(\u0026#34;相关系数矩阵:\\n\u0026#34;, corr_matrix) 结论 协方差提供关于变量之间线性关系的一些信息，但建议使用皮尔逊相关系数。\n相关系数不仅标准化了协方差，还提供了一个易于解释的度量，范围在 -1 到 1 之间。1代表存在正相关关系，-1代表负相关关系。\n","date":"2024-10-26T16:01:06+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/","title":"深度学习基础系列：协方差矩阵"},{"content":"矩阵乘法 矩阵乘法是矩阵运算的基础，简单来说，对于两个A和B矩阵来说，只要A的列数等于B的行数，那么这两个矩阵就可以发生运算\n即A是一个m x n的矩阵， B是一个n x k的矩阵，那么运算后的结果就是m x k的矩阵\n首先把矩阵转换为np.array类型，然后判断它们的类型，查看是否可以相乘\n1 2 3 4 5 6 7 8 import numpy as np def matrix_dot_vector(a:list[list[int|float]],b:list[int|float])-\u0026gt; list[int|float]: a = np.array(a) b = np.array(b) if a.shape[1] != b.shape[0]: return -1 c = np.dot(a, b) return c np.dot()接受两个数组(矩阵)并返回它们的结果\n","date":"2024-10-25T23:41:00+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/","title":"深度学习基础系列：矩阵乘法"},{"content":"在上一篇中，我们学习了如何在server上创建一个TCP的套接字，这里来看一看对于服务端，server是怎么获取客户端的连接请求的。\n获取连接请求 在开启监听(listen)后，如果有客服端尝试连接服务器，那么内核将于客户端进行连接，因为请求连接可能会有多个，所以内核会维护一个队列来存放这些请求。当客户端连接到内核之后，那么内核可以使用accept函数来返回并接受来自这个连接。\n下面来用代码演示一下\n1 2 3 4 5 6 7 8 9 10 11 # 把上次的代码复制一下 from socket import * # 创建一个套接字 # 使用socket进行初始化 serverSocket = socket(AF_INET, SOCK_STREAM) # 使用IPV4地址簇，使用的是流式socket # 接下来开始进行绑定 serverSocket.bind((\u0026#34;127.0.0.1\u0026#34;, 8080)) # bind 需要的是一个tuple类型 # 绑定后可以开始listen, 即查看是否有客户端连接到服务器 serverSocket.listen(1) # 最多监听一个 在创建好server socket之后，我们就可以使用accept函数来进行连接。这里先不考虑TCP协议在连接时的一些细节\n1 2 3 4 5 6 \u0026#39;\u0026#39;\u0026#39; 返回值： connectionSocket 客户端连接套接字 addr 连接的客户端地址 \u0026#39;\u0026#39;\u0026#39; connectionSocket，addr = serverSocket.accept() 也就是说，这个操作会返回一个新的socket,不同的是，通过这个socket就可以实现server与client之间的通讯。\n可以接受或者发送数据，下面是一些API\n1 2 3 recv()/send() recvmsg()/sendmsg() recvfrom()/sendto() 需要注意的是，传递的这些字符全部都是流式数据，与原始字符串不同\n简单的demo 在这里，创建一个简单的小demo，我们可以创建一个简单的服务程序，这个server什么也不做，只是简单的把接受到的数据原封不动的发送给client\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from socket import * # 初始化好一个socket with socket(AF_INET, SOCK_STREAM) as serverScoket: # 绑定IP和port serverScoket.bind((\u0026#34;127.0.0.1\u0026#34;, 8080)) # 开启监听listen serverScoket.listen(1) # 这是一个监听队列，当处理多个请求的时候，会把未来得及处理的放入队列里面，其中的参数表示队列的大小 # 开启socket的accept,从而处理来自server的连接 connectionSocket, _ = serverScoket.accept() # 先忽略第二个返回值 print(\u0026#39;connect!\u0026#39;) with connectionSocket as c: while True: data = c.recv(1024) # 每次都尝试获得来自客户端的数据, 注意这是个字节流数据 if not data: break c.sendall(data) # 把接受到的数据返回 我们可以使用netcat这个工具来进行测试\n1 nc 1270.0.0.1 8080 可以看到，服务器端口已经连接上了\n1 connect! 通过这个有趣的连接，我们还可以使用eval函数来实现计算式求值\neval函数是危险的！这里只是做演示\neval() 可以执行任意的 Python 代码。如果传入的字符串包含恶意代码，这可能导致严重的安全漏洞。例如，攻击者可以通过构造恶意表达式来执行系统命令、访问敏感数据、修改文件等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from socket import * # 初始化好一个socket with socket(AF_INET, SOCK_STREAM) as serverScoket: # 绑定IP和port serverScoket.bind((\u0026#34;127.0.0.1\u0026#34;, 8080)) # 开启监听listen serverScoket.listen(1) # 这是一个监听队列，当处理多个请求的时候，会把未来得及处理的放入队列里面，其中的参数表示队列的大小 # 开启socket的accept,从而处理来自server的连接 connectionSocket, _ = serverScoket.accept() # 先忽略第二个返回值 print(\u0026#39;connect!\u0026#39;) with connectionSocket as c: while True: data = c.recv(1024) # 每次都尝试获得来自客户端的数据, 注意这是个字节流数据 if not data: break # 解码接收到的数据 expression = data.decode() # 计算表达式的结果 result = str(eval(expression))+\u0026#39;\\n\u0026#39; # 发送结果给客户端 c.sendall(result.encode()) 一些缺点 浪费性能 对于真实世界来说，这里的服务器实在是太弱了\n1 2 3 4 5 while True: data = c.recv(1024) if not data: break c.sendall(data) # 把接受到的数据返回 server每次只能处理一个请求，当client没有发送数据的时候，c.recv(1024)这行代码也就会永远阻塞在这里，很浪费性能。\n此时，很自然的想到以并发的方式去处理频繁的连接\n应对策略 多进程 可以使用fork来创建多个进程，其中，fork函数在子进程里面的返回值是0，所以，可以设想一下，当有服务来临时，父进程只去监听(accept)是否有连接，同时可以把读写操作放到子进程里面去运行，这样通过进程调度策略，就可以实现并发\n代码看起来是这样的：\n1 2 3 4 5 6 7 8 while (true) { pid_t pid; if ((pid = fork()) == 0) { // 子进程 // do read() or do write() } else { // accept } } 每当一个连接到来时，程序就会创建一个子进程来处理，可惜进程实在是不够“轻量”，而且进程调度器来进行调度的时候也需要有着内核态到用户态的转换、进程的变量读写保存，因此可以考虑使用多线程来进行尝试\n多线程 什么是线程？\nIn computer science, a thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler, which is typically a part of the operating system.[1] In many cases, a thread is a component of a process.\nThe multiple threads of a given process may be executed concurrently (via multithreading capabilities), sharing resources such as memory, while different processes do not share these resources. In particular, the threads of a process share its executable code and the values of its dynamically allocated variables and non-thread-local global variables at any given time.\nThe implementation of threads and processes differs between operating systems.\n线程是进程的一个子集(你可以这么认为)，一个进程里面会有多个线程，这些线程共享这个进程所有的资源(因为它们有着一样的页表)，所以在线程切换的时候，不需要有很大的开销，只需要维护每个线程内部不共享或者私有的数据即可。\n这样就可以使用多线程来处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import threading from socket import * # 把发送请求发送这里 def handle_client(c, addr): print(addr, \u0026#39;connect\u0026#39;) while True: data = c.recv(1024) if not data: break c.sendall(data) with socket(AF_INET, SOCK_STREAM) as serverSocket: serverSocket.bind((\u0026#34;127.0.0.1\u0026#34;, 8080)) serverSocket.listen() while True: connectionSocket, addr = serverSocket.accept() # 接受多个不同的请求 t = threading.Thread(target=handle_client, args=(connectionSocket, addr)) t.start() 多线程的方法可以使用线程池的方法去调度，不过线程也会占用系统的资源。\n结尾 之后记录一下select、poll、epoll这些方法\n","date":"2024-10-21T13:19:18+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BA%8C%E6%9C%8D%E5%8A%A1%E7%AB%AF%E8%8E%B7%E5%8F%96%E8%BF%9E%E6%8E%A5%E8%AF%B7%E6%B1%82/","title":"网络编程(二)：服务端获取连接请求"},{"content":"前言 这个系列会记录所有的学习计算机网络时的笔记。\n首先计算机网络很重要(Web开发)，网络在日常生活和学习中无处不在，但是你真的了解底层的那些细节吗？比如TCP/IP协议、UDP协议，在面试的时候可能会问到相关的细节。\n参考书籍 本次参考的书籍是：\n计算机网络：自顶向下\n在此基础上，可以选择一些视频资料进行辅助，推荐一门好评较高的课程：中科大——计算机网络，同时，如果觉得学了这些知识而缺少lab来动手的话，可以参考这门lab,如果觉得过于简单，也可以挑战一下CS144.\nSocket Socket的中文翻译是套接字，这个翻译很难理解，你可以把它认为是一个接口，插座之类的物品，或者认为它是一个介质。在日常生活中，很多都是Client-Server的模式，即客户端请求服务器上的一些资源，服务器在收到客户端的请求之后把数据发送到给客户端，这些数据就是通过套接字来实现的传输的。\n套接字（Socket）是一个抽象层，应用程序可以通过它发送或接收数据，可对其进行像对文件一样的打开、读写和关闭等操作。套接字允许应用程序将 I/O 插入到网络中，并与网络中的其他应用程序进行通信。\n网络套接字是 IP 地址与端口 Port 的组合。\n为了满足不同的通信程序对通信质量和性能的要求，网络系统提供了三种不同类型的套接字，以供用户在设计网络应用程序时根据不同的要求来选择。分别是：\n流式套接字（SOCK-STREAM）。提供一种可靠的、面向连接的双向数据传输服务，**实现了数据无差错、无重复的发送。**流式套接字内设流量控制，被传输的数据看作是无记录边界的字节流。在 TCP/IP 协议簇中，使用 TCP 协议来实现字节流的传输，当用户想要发送大批量的数据或者对数据传输有较高的要求时，可以使用流式套接字。 数据报套接字（SOCK-DGRAM）。提供一种无连接、不可靠的双向数据传输服务。数据包以独立的形式被发送，并且保留了记录边界，不提供可靠性保证。数据在传输过程中可能会丢失或重复，并且不能保证在接收端按发送顺序接收数据。在 TCP/IP 协议簇中，使用 UDP 协议来实现数据报套接字。在出现差错的可能性较小或允许部分传输出错的应用场合，可以使用数据报套接字进行数据传输，这样通信的效率较高。 原始套接字（SOCK-RAW）。该套接字允许对较低层协议（如 IP 或 ICMP ）进行直接访问，常用于网络协议分析，检验新的网络协议实现，也可用于测试新配置或安装的网络设备。 这里需要记住两种协议：TCP和UDP，先不考虑它们底层是怎么实现的，TCP的特点就是可以保证在传送的过程中数据不丢失、不重复、不乱序，原原本本的把数据发送给接受者；而UDP协议考虑的很少，所以UDP协议可以用于传输速度快的场景。\n创建Socket 这里为了简单起见，使用Python来创建\n1 2 3 4 5 6 7 8 # 导入socket包 from socket import * # 创建一个TCP套接字 serverSocket = socket(AF_INET, SOCK_STREAM) # TCP是流式套接字 # 绑定Server的IP和Port serverSocket.bind((\u0026#34;127.0.0.1\u0026#34;, 8080)) # bind的参数是tuple类型，需要一个地址和端口 到这里，已经成功把serverSocket绑定到IP地址为127.0.0.1:8080的机器上了\n监听listen 在创建好serverSocket后，因为不知道什么时候server会收到连接请求，一个有效的方法是listen函数\n1 serverSocket.listen(1) 这里，函数的参数是监听队列的大小，当有多个连接请求时，这些请求会被放到监听队列里面。\n到目前为止，我们可以看一看serverSocket的一些信息\n1 print(ServerSocket) 下面是输出信息\n1 \u0026lt;socket.socket fd=340, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=(\u0026#39;127.0.0.1\u0026#39;, 8080)\u0026gt; 其中，第一个参数fd你可能不太了解，这个是一个文件描述符(file descriptor)，文件描述符是一个Obj的handle，或者你也可以理解为指向文件的指针，在Unix和类Unix系统中，所有的I/O都被抽象为文件描述符，包括网络套接字。\n流程 在创建一个socket时，可以遵循以下步骤\n根据协议初始化一个socket 给socket绑定IP 开启监听 关闭这个socket,防止内存泄漏 好，这就是创建socket的所有过程~~\n","date":"2024-10-20T17:31:13+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%B8%80%E5%88%9D%E8%AF%86%E5%A5%97%E6%8E%A5%E5%AD%97/","title":"网络编程(一)：初识套接字"},{"content":"堆结构 许多应用程序都需要处理有序的元素，但是不一定要求它们全部有序，或是不一定要一次就将它们完全排好序。例如，你要实现一个进程调度算法，每一个进程都有一个优先级(当有电话到来时，你的游戏很可能会被打断)，所以电话程序的优先级会高于游戏程序的优先级。\n所以当前面临的挑战是：一个电脑上每个时刻都会有许多不同的进程，怎么按照优先级去调度它们呢？也就是说，在每次调度的时候，我们都希望花费很少的时间去找到最重要的进程(或者最不重要的进程)，堆结构就很好的解决这个问题。\n完全二叉树 二叉树是一种常见的结构，对于一个结点来说，它通常可以有两个子节点(left, right)，看起来是这样的：\n1 2 3 3 1 2 4 5 6 7 用代码来表示：\n1 2 3 4 5 type Tree struct { Val int // 值域 Left *Tree Right *Tree } 不过这里我们不会使用这种形式，可以使用数组来进行父子结点之间关系。\n完全二叉树是一个特殊的二叉树，下面是维基百科对完全二叉树的介绍\n在一颗二叉树中，若除最后一层外的其余层都是满的，并且最后一层要么是满的，要么在右边缺少连续若干节点，则此二叉树为完全二叉树（Complete Binary Tree）。具有n个节点的完全二叉树的深度。深度为k的完全二叉树，至少有个节点，至多有个节点。\n通俗点来说，完全二叉树就是满二叉树从后向前去除子节点后剩下的二叉树。简单来说，堆按照根节点与子节点的大小关系可以分为大根堆和小根堆。大根堆的根节点比所有的子节点大，小根堆的根节点比子节点都小。所以按照这种规则，大根堆的根节点一定是数组里面的最大值，小根堆的根节点一定是数组里面的最小值。\n堆的实现 首先，对于一个不是堆结构的数组来说，第一步要做的就是heapify堆化，堆化需要用到两个辅助函数，\n就是 sink和swim。\n从名字上来看，sink就是向下交换，swim就是向上交换，对于一个数组，我们可以从第一个非叶子结点开始堆化，对于这些非叶子结点，我们每次都进行堆化，这样初始化到数组的第一个元素的时候，整个数组就是堆结构了。\nsink方法 首先是找到这个数组的第一个非叶子结点，对于一个数组arr来说，我们假定它的长度是n，那么它的第一个非叶子结点就是(n-1) / 2，这里从大根堆开始建堆.\n首先，一个堆结构看起来可能是这样的：\n1 2 3 type MaxHeap struct { item []int } 它的sink方法是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func (this *MaxHeap) sink(k int) { n := len(this.item) // 孩子结点 for 2*k+1 \u0026lt; n { child := 2*k + 1 if child+1 \u0026lt; n \u0026amp;\u0026amp; this.item[child] \u0026lt; this.item[child+1] { child = child + 1 } // 没必要交换 if this.item[k] \u0026gt;= this.item[child] { break } // 交换两个元素 this.item[k], this.item[child] = this.item[child], this.item[k] k = child } } 上面这段代码的意思是，给定一个下标，让这个下标的元素向下交换，从而满足堆结构。然后就可以开始进行堆化的操作了\nheapify方法 1 2 3 4 5 6 7 func (this *MaxHeap) heapify() { // 从非叶子结点开始 n := len(this.item) for i := (n - 1) / 2; i \u0026gt;= 0; i-- { this.sink(i) } } 经过此次操作，我们就已经有了堆结构，item切片的第一个元素就是数组中的最大值。\nswim方法 但是，到目前为止，我们还没有让这个堆实现动态数据的添加和实现，当新增一个数据的时候，我们就把它添加到切片的结尾末尾，此时，这个新增的结点很可能会破坏掉原来的堆结构，这个时候，我们应该给新添加进来的元素找到合适的位置，swim方法就可以很好的实现。\n1 2 3 4 5 6 7 func (this *MaxHeap) swim(k int) { for k \u0026gt; 0 \u0026amp;\u0026amp; this.item[(k-1)/2] \u0026lt; this.item[k] { // 父节点比自己小 this.item[(k-1)/2], this.item[k] = this.item[k], this.item[(k-1)/2] k = (k - 1) / 2 // 注意这里啊 } } 添加与删除 添加一个元素时，需要动态的调整位置\n1 2 3 4 func (this *MaxHeap) insert(val int) { this.item = append(this.item, val) this.swim(len(this.item) - 1) } 删除一个元素的时候(一般是根节点)，这里有一个trick，根节点与最后一个结点进行交换，然后再把新的结点sink使得找到合适的位置，这样做是因为，数组不适合频繁的添加删除元素，这样做可以更加高效！\n1 2 3 4 5 6 7 8 9 10 func (this *MaxHeap) delMax() int { ans := this.item[0] this.item[0], this.item[len(this.item)-1] = this.item[len(this.item)-1], this.item[0] this.item = this.item[:len(this.item)-1] // 删除 this.sink(0) return ans } func (this *MaxHeap) getMax() int { return this.item[0] } 到此，我们就成功的实现了一个大顶堆，小顶堆的实现与之很相似，这里直接贴出代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 type MinHeap struct { item []int } func (this *MinHeap) heapify(nums []int) { this.item = nums n := len(this.item) for i := (n - 1) / 2; i \u0026gt;= 0; i-- { this.sink(i) } } func (this *MinHeap) sink(k int) { n := len(this.item) for 2*k+1 \u0026lt; n { child := 2*k + 1 if child+1 \u0026lt; n \u0026amp;\u0026amp; this.item[child+1] \u0026lt; this.item[child] { child = child + 1 } if this.item[k] \u0026lt;= this.item[child] { break } this.item[k], this.item[child] = this.item[child], this.item[k] k = child } } func (this *MinHeap) swim(k int) { for k \u0026gt; 0 \u0026amp;\u0026amp; this.item[(k-1)/2] \u0026gt; this.item[k] { this.item[k], this.item[(k-1)/2] = this.item[(k-1)/2], this.item[k] k = (k - 1) / 2 } } func (this *MinHeap) genLength() int { return len(this.item) } func (this *MinHeap) insert(val int) { this.item = append(this.item, val) this.swim(len(this.item) - 1) } 拓展：堆排序 在我们刚才构建大顶堆的时候，注意到每次都可以以 $O(logK)$的时间复杂度调整并获取最大值，所以，对于n组数来说，我们就可以以$O(nlogK)$的复杂度来进行排序，其中$K$是树的高度\n这里是完整代码，需要注意交换的范围每次都是在缩小的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package main import ( \u0026#34;fmt\u0026#34; ) // ConstructMaxHeap 将输入数组转换为最大堆。 func ConstructMaxHeap(nums []int) { n := len(nums) for i := n/2 - 1; i \u0026gt;= 0; i-- { sink(nums, i, n) } } // sink 是辅助函数，用于下沉元素以保持最大堆性质。 func sink(nums []int, k int, n int) { for 2*k+1 \u0026lt; n { child := 2*k + 1 if child+1 \u0026lt; n \u0026amp;\u0026amp; nums[child] \u0026lt; nums[child+1] { child = child + 1 } if nums[k] \u0026gt;= nums[child] { break } nums[k], nums[child] = nums[child], nums[k] k = child } } // heapSort 使用堆排序算法对输入的切片进行排序。 func heapSort(nums []int) { ConstructMaxHeap(nums) n := len(nums) for i := n - 1; i \u0026gt; 0; i-- { nums[i], nums[0] = nums[0], nums[i] // 交换最大元素到正确位置 sink(nums, 0, i) // 重新构建堆 } } func main() { nums := []int{3, 2, 1, 5, 6, 4} fmt.Println(\u0026#34;Original array:\u0026#34;, nums) heapSort(nums) fmt.Println(\u0026#34;Sorted array:\u0026#34;, nums) } ","date":"2024-10-19T19:47:58+08:00","permalink":"https://XiaoPeng0x3.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%A0%86/","title":"数据结构之堆"}]